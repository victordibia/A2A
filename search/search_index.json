{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#a2a-unlock-collaborative-agent-to-agent-scenarios-with-a-new-open-protocol","title":"A2A: Unlock collaborative agent-to-agent scenarios with a new open protocol","text":"<ul> <li> <p>Seamless Agent Collaboration: Introduces a standard protocol for autonomous,   opaque agents built on different frameworks and by various vendors to   communicate and collaborate effectively with each other and with users,   addressing the current lack of agent interoperability.</p> </li> <li> <p>Simplifies Enterprise Agent Integration: Provides a straightforward way to   integrate intelligent agents into existing enterprise applications, allowing   businesses to leverage agent capabilities across their technology landscape.</p> </li> <li> <p>Supports Key Enterprise Requirements: Offers core functionalities essential   for secure, enterprise-grade agent ecosystems, including capability discovery,   user experience negotiation, task and state management, and secure   collaboration. Open standards for connecting Agents</p> </li> </ul> <p></p> <ul> <li>MCP (Model Context Protocol) for tools and resources<ul> <li>Connect agents to tools, APIs, and resources with structured inputs/outputs.</li> <li>Google ADK supports MCP tools. Enabling wide range of MCP servers to be used with agents.</li> </ul> </li> <li>A2A (Agent2Agent Protocol) for agent-agent collaboration<ul> <li>Dynamic, multimodal communication between different agents without sharing memory, resources, and tools</li> <li>Open standard driven by community.</li> <li>Samples available using Google ADK, LangGraph, Crew.AI</li> </ul> </li> </ul>"},{"location":"#community-feedback-and-roadmap","title":"Community Feedback and Roadmap","text":"<p>A2A is a work in progress and is expected to change based on community feedback. This repo contains the initial specification, documentation, and sample code. We will continue to update this repository with more features, more examples, specs, and libraries as they become available. When the spec and samples can graduate to a production quality SDK, we will declare version 1.0 and maintain stable releases.</p> <p>To understand A2A design principles and external partners supporting A2A, read our blog post on Announcing the Agent2Agent Protocol (A2A).</p> <p>Interested to contribute and know more about the internals of A2A protocol? Join our GitHub repository!</p>"},{"location":"community/","title":"Welcome to the A2A Community","text":"<p>The Agent2Agent (A2A) protocol is generating significant buzz across the tech world, and for good reason! This open interoperability protocol is designed to enable seamless collaboration between AI agents across diverse frameworks and vendors. By standardizing communication, A2A aims to unlock complex workflows, enhance productivity, and foster a new era of \"Agent Interoperability\". Don't just take our word for it \u2013 see what the community is saying!</p>"},{"location":"community/#the-word-on-the-street-social-highlights","title":"The Word on the Street: Social Highlights","text":"<p>The launch of A2A has sparked lively discussions and positive reactions on various social platforms. Here's a glimpse of the excitement:</p> <ul> <li> <p>Rapid Interest and Adoption: The A2A GitHub repository has seen an explosive surge in popularity. This rapid interest underscores the industry's eagerness for a standardized agent communication protocol, with many companies collaborating and contributing.</p> </li> <li> <p>Microsoft's interest via Semantic Kernel: Asha Sharma, Head of AI Platform Product at Microsoft, announced on LinkedIn that \"Semantic Kernel now speaks A2A: a lightweight JSON-RPC protocol that lets agents swap context, not code or credentials, over plain HTTP. Drop it into your Foundry stack for instant, secure, async interoperability with any A2A-compliant agent, regardless of modality\". The post received numerous positive reactions, including \"A2A support in Semantic Kernel is a key unlock \u2014 context-level interoperability without sharing code or creds is how agent ecosystems scale securely across clouds\".</p> </li> <li> <p>Matt Pocock's Diagramming Intent: Matt Pocock, a well-known developer educator, shared on X, \"I've just been reading the Agent2Agent technical docs - Google's new protocol for agent to agent communication. You know what that means. Let's diagram them:\". This tweet, liked and reposted hundreds of times, includes some great diagrams explaining the A2A protocol.</p> </li> <li> <p>Craig McLuckie's \"Hot Take\": Craig McLuckie shared his initial thoughts on LinkedIn, calling it a \"Hot take on Agent2Agent vs MCP\". His post highlighted Google's careful positioning of A2A as focused on interactions between agentic systems, rather than agents interacting with resources (the focus of MCP). This distinction is crucial for improving models' ability to understand expectations from other agents. McLuckie also pointed out the potential for A2A to enable systems to advertise specific capabilities and specialities, which is seen as \"sensible\".</p> </li> </ul>"},{"location":"community/#community-deep-dive-videos","title":"Community deep dive videos","text":"<ul> <li>Zachary Huang explains in his YouTube video, A2A \"complements\" MCP. While MCP acts as a \"USB-C port for AI applications\" connecting agents to tools, A2A acts as a communication standard between the intelligent agents themselves. This layered approach allows for building powerful systems where agents use A2A to coordinate and MCP to access necessary tools.</li> <li>Jack Herrington on his YouTube video walks through some of the provided examples and closes with his opinion that \"Having a specific protocol for agents to talk to other agents is valuable\" and reiterates, \"LLM plus tools are agents. MCP gives agents those tools. So that's why A2A and MCP play really nicely together\".</li> <li>Cole Medin suggested on his YouTube video that \"A2A was released very recently but it's already looking like it's going to follow a similar path\" to MCP in terms of growing interest. He also demonstrates the samples step by step and provides a summary of core concepts.</li> <li>Sam Witteveen covered A2A on his YouTube video immediately after Google Cloud Next and discusses the value of making protocols open and not ending up with conflicting protocols.</li> </ul>"},{"location":"community/#community-contributions-to-a2a","title":"Community Contributions to A2A","text":"<ul> <li>LlamaIndex submitted a sample implementation PR#179</li> <li>Autogen sample server PR#232</li> <li>AG2 + MCP example PR#230</li> <li>PydanticAI example PR#127</li> <li>Go example PR#52</li> <li>Daytona sandbox running agent PR#170</li> </ul>"},{"location":"community/#what-is-driving-this-excitement","title":"What is Driving This Excitement?","text":"<p>The enthusiasm surrounding A2A stems from its potential to address key challenges in building sophisticated AI applications:</p> <ul> <li> <p>Breaking Down Silos: A2A aims to overcome the limitations of siloed AI systems by providing a universal framework for agents built on different platforms to communicate and collaborate securely.</p> </li> <li> <p>Enabling Complex Collaboration: For tasks that require the expertise of multiple specialized agents, A2A provides a standardized way for them to delegate tasks, exchange information, and coordinate actions. This mirrors how human teams work together, distributing responsibilities for greater efficiency.</p> </li> <li> <p>Dynamic Agent Discovery: A key feature of A2A is the ability for agents to discover the capabilities of other agents through standardized \"Agent Cards\". This dynamic discovery allows for more flexible and adaptable multi-agent systems.</p> </li> <li> <p>Complementary to MCP: As stated on our A2A \u2764\ufe0f MCP topic page and affirmed by many community, A2A \"complements\" MCP. MCP acts as a communication standard between models and resources, providing tools for agents. A2A acts as a communication standard between the intelligent agents themselves. This layered approach allows for building powerful systems where agents use A2A to coordinate and MCP to access necessary tools.</p> </li> <li> <p>Open and Community-Driven: Google has released A2A as open source, inviting contributions from the broader community to refine and expand its functionality. This commitment to open collaboration fosters innovation and broad adoption.</p> </li> </ul>"},{"location":"community/#the-future-is-interoperable","title":"The Future is Interoperable","text":"<p>The social media buzz surrounding Google's A2A protocol clearly indicates a strong interest and belief in its potential to revolutionize the development of multi-agent AI systems. By providing a standardized way for AI agents to communicate and collaborate, A2A is poised to unlock new levels of automation, efficiency, and innovation. As enterprises increasingly adopt AI agents for a wide range of tasks, A2A represents a crucial step towards realizing the full power of interconnected AI ecosystems.</p> <p>Stay tuned for more updates and join the growing community building the future of AI interoperability with A2A!</p>"},{"location":"documentation/","title":"Agent2Agent Protocol (A2A)","text":"<p>An open protocol enabling Agent-to-Agent interoperability, bridging the gap between opaque agentic systems.</p> <p></p>"},{"location":"documentation/#key-principles","title":"Key Principles","text":"<p>Using A2A, agents accomplish tasks for end users without sharing memory, thoughts, or tools. Instead the agents exchange context, status, instructions, and data in their native modalities.</p> <ul> <li>Simple: Reuse existing standards</li> <li>Enterprise Ready: Auth, Security, Privacy, Tracing, Monitoring</li> <li>Async First: (Very) Long running-tasks and human-in-the-loop</li> <li>Modality Agnostic: text, audio/video, forms, iframe, etc.</li> <li>Opaque Execution: Agents do not have to share thoughts, plans, or tools.</li> </ul>"},{"location":"documentation/#more-detailed-discussions","title":"More Detailed Discussions","text":"<ul> <li>A2A and MCP</li> <li>Enterprise Ready</li> <li>Push Notifications</li> <li>Agent Discovery</li> </ul>"},{"location":"documentation/#overview","title":"Overview","text":""},{"location":"documentation/#actors","title":"Actors","text":"<p>The A2A protocol has three actors:</p> <ul> <li>User   The end user (human or service) that is using an agentic system to accomplish tasks.</li> <li>Client   The entity (service, agent, application) that is requesting an action from an opaque agent on behalf of the user.</li> <li>Remote Agent (Server)   The opaque (\"black box\") agent which is the A2A server.</li> </ul>"},{"location":"documentation/#transport","title":"Transport","text":"<p>The protocol leverages HTTP for transport between the client and the remote agent. Depending on the capabilities of the client and the remote agent, they may leverage SSE for supporting streaming for receiving updates from the server.</p> <p>A2A leverages JSON-RPC 2.0 as the data exchange format for communication between a Client and a Remote Agent.</p>"},{"location":"documentation/#async","title":"Async","text":"<p>A2A clients and servers can use standard request/response patterns and poll for updates. However, A2A also supports streaming updates through SSE (while connected) and receiving push notifications while disconnected.</p>"},{"location":"documentation/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>A2A models agents as enterprise applications (and can do so because A2A agents are opaque and do not share tools and resources). This quickly brings enterprise-readiness to agentic interop.</p> <p>A2A follows OpenAPI's Authentication specification for authentication. Importantly, A2A agents do not exchange identity information within the A2A protocol. Instead, they obtain materials (such as tokens) out of band and transmit materials in HTTP headers and not in A2A payloads.</p> <p>While A2A does not transmit identity in-band, servers do send authentication requirements in A2A payloads. At minimum, servers are expected to publish their requirements in their Agent Card. Thoughts about discovering agent cards are in this topic.</p> <p>Clients should use one of the servers published authentication protocols to authenticate their identity and obtain credential material. A2A servers should authenticate every request and reject or challenge requests with standard HTTP response codes (401, 403), and authentication-protocol-specific headers and bodies (such as a HTTP 401 response with a WWW-Authenticate header indicating the required authentication schema, or OIDC discovery document at a well-known path). More details discussed in Enterprise Ready.</p> <p>Note: If an agent requires that the client/user provide additional credentials during execution of a task (for example, to use a specific tool), the agent should return a task status of <code>Input-Required</code> with the payload being an Authentication structure. The client should, again, obtain credential material out of band to A2A.</p>"},{"location":"documentation/#agent-card","title":"Agent Card","text":"<p>Remote Agents that support A2A are required to publish an Agent Card in JSON format describing the agent's capabilities/skills and authentication mechanism. Clients use the Agent Card information to identify the best agent that can perform a task and leverage A2A to communicate with that remote agent.</p>"},{"location":"documentation/#discovery","title":"Discovery","text":"<p>We recommend agents host their Agent Card at <code>https://DOMAIN/.well-known/agent.json</code>. This is compatible with a DNS approach where the client finds the server IP via DNS and sends an HTTP <code>GET</code> to retrieve the agent card. We also anticipate that systems will maintain private registries (e.g. an 'Agent Catalog' or private marketplace, etc). More discussion can be found in this document.</p>"},{"location":"documentation/#representation","title":"Representation","text":"<p>Following is the proposed representation of an Agent Card</p> <pre><code>// An AgentCard conveys key information:\n// - Overall details (version, name, description, uses)\n// - Skills: A set of capabilities the agent can perform\n// - Default modalities/content types supported by the agent.\n// - Authentication requirements\ninterface AgentCard {\n  // Human readable name of the agent.\n  // (e.g. \"Recipe Agent\")\n  name: string;\n  // A human-readable description of the agent. Used to assist users and\n  // other agents in understanding what the agent can do.\n  // (e.g. \"Agent that helps users with recipes and cooking.\")\n  description: string;\n  // A URL to the address the agent is hosted at.\n  url: string;\n  // The service provider of the agent\n  provider?: {\n    organization: string;\n    url: string;\n  };\n  // The version of the agent - format is up to the provider. (e.g. \"1.0.0\")\n  version: string;\n  // A URL to documentation for the agent.\n  documentationUrl?: string;\n  // Optional capabilities supported by the agent.\n  capabilities: {\n    streaming?: boolean; // true if the agent supports SSE\n    pushNotifications?: boolean; // true if the agent can notify updates to client\n    stateTransitionHistory?: boolean; //true if the agent exposes status change history for tasks\n  };\n  // Authentication requirements for the agent.\n  // Intended to match OpenAPI authentication structure.\n  authentication: {\n    schemes: string[]; // e.g. Basic, Bearer\n    credentials?: string; //credentials a client should use for private cards\n  };\n  // The set of interaction modes that the agent\n  // supports across all skills. This can be overridden per-skill.\n  defaultInputModes: string[]; // supported mime types for input\n  defaultOutputModes: string[]; // supported mime types for output\n  // Skills are a unit of capability that an agent can perform.\n  skills: {\n    id: string; // unique identifier for the agent's skill\n    name: string; //human readable name of the skill\n    // description of the skill - will be used by the client or a human\n    // as a hint to understand what the skill does.\n    description: string;\n    // Set of tag words describing classes of capabilities for this specific\n    // skill (e.g. \"cooking\", \"customer support\", \"billing\")\n    tags: string[];\n    // The set of example scenarios that the skill can perform.\n    // Will be used by the client as a hint to understand how the skill can be\n    // used. (e.g. \"I need a recipe for bread\")\n    examples?: string[]; // example prompts for tasks\n    // The set of interaction modes that the skill supports\n    // (if different than the default)\n    inputModes?: string[]; // supported mime types for input\n    outputModes?: string[]; // supported mime types for output\n  }[];\n}\n</code></pre>"},{"location":"documentation/#agent-to-agent-communication","title":"Agent-to-Agent Communication","text":"<p>The communication between a Client and a Remote Agent is oriented towards task completion where agents collaboratively fulfill an end user's request. A Task object allows a Client and a Remote Agent to collaborate for completing the submitted task.</p> <p>A task can be completed by a remote agent immediately or it can be long-running. For long-running tasks, the client may poll the agent for fetching the latest status. Agents can also push notifications to the client via SSE (if connected) or through an external notification service.</p>"},{"location":"documentation/#core-objects","title":"Core Objects","text":""},{"location":"documentation/#task","title":"Task","text":"<p>A Task is a stateful entity that allows Clients and Remote Agents to achieve a specific outcome and generate results. Clients and Remote Agents exchange Messages within a Task. Remote Agents generate results as Artifacts.</p> <p>A Task is always created by a Client and the status is always determined by the Remote Agent. Multiple Tasks may be part of a common session (denoted by optional sessionId) if required by the client. To do so, the Client sets an optional sessionId when creating the Task.</p> <p>The agent may:</p> <ul> <li>fulfill the request immediately</li> <li>schedule work for later</li> <li>reject the request</li> <li>negotiate a different modality</li> <li>ask the client for more information</li> <li>delegate to other agents and systems</li> </ul> <p>Even after fulfilling the goal, the client can request more information or a change in the context of that same Task. (For example client: \"draw a picture of a rabbit\", agent: \"&lt;picture&gt;\", client: \"make it red\").</p> <p>Tasks are used to transmit Artifacts (results) and Messages (thoughts, instructions, anything else). Tasks maintain a status and an optional history of status and Messages.</p> <pre><code>interface Task {\n  id: string; // unique identifier for the task\n  sessionId: string; // client-generated id for the session holding the task.\n  status: TaskStatus; // current status of the task\n  history?: Message[];\n  artifacts?: Artifact[]; // collection of artifacts created by the agent.\n  metadata?: Record&lt;string, any&gt;; // extension metadata\n}\n// TaskState and accompanying message.\ninterface TaskStatus {\n  state: TaskState;\n  message?: Message; //additional status updates for client\n  timestamp?: string; // ISO datetime value\n}\n// sent by server during sendSubscribe or subscribe requests\ninterface TaskStatusUpdateEvent {\n  id: string; //Task id\n  status: TaskStatus;\n  final: boolean; //indicates the end of the event stream\n  metadata?: Record&lt;string, any&gt;;\n}\n// sent by server during sendSubscribe or subscribe requests\ninterface TaskArtifactUpdateEvent {\n  id: string; //Task id\n  artifact: Artifact;\n  metadata?: Record&lt;string, any&gt;;\n}\n// Sent by the client to the agent to create, continue, or restart a task.\ninterface TaskSendParams {\n  id: string;\n  sessionId?: string; //server creates a new sessionId for new tasks if not set\n  message: Message;\n  historyLength?: number; //number of recent messages to be retrieved\n  // where the server should send notifications when disconnected.\n  pushNotification?: PushNotificationConfig;\n  metadata?: Record&lt;string, any&gt;; // extension metadata\n}\ntype TaskState =\n  | \"submitted\"\n  | \"working\"\n  | \"input-required\"\n  | \"completed\"\n  | \"canceled\"\n  | \"failed\"\n  | \"unknown\";\n</code></pre>"},{"location":"documentation/#artifact","title":"Artifact","text":"<p>Agents generate Artifacts as an end result of a Task. Artifacts are immutable, can be named, and can have multiple parts. A streaming response can append parts to existing Artifacts.</p> <p>A single Task can generate many Artifacts. For example, \"create a webpage\" could create separate HTML and image Artifacts.</p> <pre><code>interface Artifact {\n  name?: string;\n  description?: string;\n  parts: Part[];\n  metadata?: Record&lt;string, any&gt;;\n  index: number;\n  append?: boolean;\n  lastChunk?: boolean;\n}\n</code></pre>"},{"location":"documentation/#message","title":"Message","text":"<p>A Message contains any content that is not an Artifact. This can include things like agent thoughts, user context, instructions, errors, status, or metadata.</p> <p>All content from a client comes in the form of a Message. Agents send Messages to communicate status or to provide instructions (whereas generated results are sent as Artifacts).</p> <p>A Message can have multiple parts to denote different pieces of content. For example, a user request could include a textual description from a user and then multiple files used as context from the client.</p> <pre><code>interface Message {\n  role: \"user\" | \"agent\";\n  parts: Part[];\n  metadata?: Record&lt;string, any&gt;;\n}\n</code></pre>"},{"location":"documentation/#part","title":"Part","text":"<p>A fully formed piece of content exchanged between a client and a remote agent as part of a Message or an Artifact. Each Part has its own content type and metadata.</p> <pre><code>interface TextPart {\n  type: \"text\";\n  text: string;\n}\ninterface FilePart {\n  type: \"file\";\n  file: {\n    name?: string;\n    mimeType?: string;\n    // oneof {\n    bytes?: string; //base64 encoded content\n    uri?: string;\n    //}\n  };\n}\ninterface DataPart {\n  type: \"data\";\n  data: Record&lt;string, any&gt;;\n}\ntype Part = (TextPart | FilePart | DataPart) &amp; {\n  metadata: Record&lt;string, any&gt;;\n};\n</code></pre>"},{"location":"documentation/#push-notifications","title":"Push Notifications","text":"<p>A2A supports a secure notification mechanism whereby an agent can notify a client of an update outside of a connected session via a PushNotificationService. Within and across enterprises, it is critical that the agent verifies the identity of the notification service, authenticates itself with the service, and presents an identifier that ties the notification to the executing Task.</p> <p>The target server of the PushNotificationService should be considered a separate service, and is not guaranteed (or even expected) to be the client directly. This PushNotificationService is responsible for authenticating and authorizing the agent and for proxying the verified notification to the appropriate endpoint (which could be anything from a pub/sub queue, to an email inbox or other service, etc).</p> <p>For contrived scenarios with isolated client-agent pairs (e.g. local service mesh in a contained VPC, etc.) or isolated environments without enterprise security concerns, the client may choose to simply open a port and act as its own PushNotificationService. Any enterprise implementation will likely have a centralized service that authenticates the remote agents with trusted notification credentials and can handle online/offline scenarios. (This should be thought of similarly to a mobile Push Notification Service).</p> <pre><code>interface PushNotificationConfig {\n  url: string;\n  token?: string; // token unique to this task/session\n  authentication?: {\n    schemes: string[];\n    credentials?: string;\n  };\n}\ninterface TaskPushNotificationConfig {\n  id: string; //task id\n  pushNotificationConfig: PushNotificationConfig;\n}\n</code></pre>"},{"location":"documentation/#sample-methods-and-json-responses","title":"Sample Methods and JSON Responses","text":""},{"location":"documentation/#sample-agent-card","title":"Sample Agent Card","text":"<pre><code>{\n  \"name\": \"Google Maps Agent\",\n  \"description\": \"Plan routes, remember places, and generate directions\",\n  \"url\": \"https://maps-agent.google.com\",\n  \"provider\": {\n    \"organization\": \"Google\",\n    \"url\": \"https://google.com\"\n  },\n  \"version\": \"1.0.0\",\n  \"authentication\": {\n    \"schemes\": \"OAuth2\"\n  },\n  \"defaultInputModes\": [\"text/plain\"],\n  \"defaultOutputModes\": [\"text/plain\", \"application/html\"],\n  \"capabilities\": {\n    \"streaming\": true,\n    \"pushNotifications\": false\n  },\n  \"skills\": [\n    {\n      \"id\": \"route-planner\",\n      \"name\": \"Route planning\",\n      \"description\": \"Helps plan routing between two locations\",\n      \"tags\": [\"maps\", \"routing\", \"navigation\"],\n      \"examples\": [\n        \"plan my route from Sunnyvale to Mountain View\",\n        \"what's the commute time from Sunnyvale to San Francisco at 9AM\",\n        \"create turn by turn directions from Sunnyvale to Mountain View\"\n      ],\n      // can return a video of the route\n      \"outputModes\": [\"application/html\", \"video/mp4\"]\n    },\n    {\n      \"id\": \"custom-map\",\n      \"name\": \"My Map\",\n      \"description\": \"Manage a custom map with your own saved places\",\n      \"tags\": [\"custom-map\", \"saved-places\"],\n      \"examples\": [\n        \"show me my favorite restaurants on the map\",\n        \"create a visual of all places I've visited in the past year\"\n      ],\n      \"outputModes\": [\"application/html\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"documentation/#send-a-task","title":"Send a Task","text":"<p>Allows a client to send content to a remote agent to start a new Task, resume an interrupted Task, or reopen a completed Task. A Task interrupt may be caused by an agent requiring additional user input or a runtime error.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"tell me a joke\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"name\": \"joke\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Why did the chicken cross the road? To get to the other side!\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"documentation/#get-a-task","title":"Get a Task","text":"<p>Clients may use this method to retrieve the generated Artifacts for a Task. The agent determines the retention window for Tasks previously submitted to it. An agent may return an error code for Tasks that were past the retention window or for Tasks that are short-lived and not persisted.</p> <p>The client may also request the last N items of history for the Task, which will include all Messages, in order, sent by the client and server. By default, this is 0 (no history).</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"historyLength\": 10,\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Why did the chicken cross the road? To get to the other side!\"\n          }\n        ]\n      }\n    ],\n    \"history\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"tell me a joke\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"documentation/#cancel-a-task","title":"Cancel a Task","text":"<p>A client may choose to cancel previously submitted Tasks.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/cancel\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"canceled\"\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"documentation/#set-task-push-notifications","title":"Set Task Push Notifications","text":"<p>Clients may configure a push notification URL for receiving an update on Task status change.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/pushNotification/set\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"documentation/#get-task-push-notifications","title":"Get Task Push Notifications","text":"<p>Clients may retrieve the currently configured push notification configuration for a Task using this method.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/pushNotification/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"documentation/#multi-turn-conversations","title":"Multi-turn Conversations","text":"<p>A Task may pause execution on the remote agent if it requires additional user input. When a Task is in the <code>input-required</code> state, the client must provide additional input for the Task to resume processing.</p> <p>The Message included in the <code>input-required</code> state must include details indicating what the client must do (e.g., \"fill out a form\", \"log into SaaS service foo\"). If this includes structured data, the instruction should be sent as one <code>Part</code> and the structured data as a second <code>Part</code>.</p> <p>Request (Sequence 1):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"request a new phone for me\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 2 - Input Required):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"input-required\",\n      \"message\": {\n        \"role\": \"agent\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Select a phone type (iPhone/Android)\"\n          }\n        ]\n      }\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Request (Sequence 3 - Providing Input):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Android\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 4 - Completion):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"name\": \"order-confirmation\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"I have ordered a new Android device for you. Your request number is R12443\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"documentation/#streaming-support","title":"Streaming Support","text":"<p>For clients and remote agents capable of communicating over HTTP with Server-Sent Events (SSE), clients can send the RPC request with method <code>tasks/sendSubscribe</code> when creating a new Task. The remote agent can respond with a stream of <code>TaskStatusUpdateEvents</code> (to communicate status changes or instructions/requests) and <code>TaskArtifactUpdateEvents</code> (to stream generated results).</p> <p>Note that <code>TaskArtifactUpdateEvents</code> can append new parts to existing Artifacts. Clients can use <code>tasks/get</code> to retrieve the entire Artifact outside of the streaming context. Agents must set the <code>final: true</code> attribute at the end of the stream or if the agent is interrupted and requires additional user input.</p> <p>Request:</p> <pre><code>{\n  \"method\": \"tasks/sendSubscribe\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"write a long paper describing the attached pictures\"\n        },\n        {\n          \"type\": \"file\",\n          \"file\": {\n            \"mimeType\": \"image/png\",\n            \"data\": \"&lt;base64-encoded-content&gt;\"\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (SSE Stream):</p> <pre><code>data: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"status\": {\n      \"state\": \"working\",\n      \"timestamp\":\"2025-04-02T16:59:25.331844\"\n    },\n    \"final\": false\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 1...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": false,\n      \"lastChunk\": false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 2...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": 1,\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 3...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": true\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": 1,\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\":\"2025-04-02T16:59:35.331844\"\n    },\n    \"final\": true\n  }\n}\n</code></pre>"},{"location":"documentation/#resubscribe-to-task","title":"Resubscribe to Task","text":"<p>A disconnected client may resubscribe to a remote agent that supports streaming to receive Task updates via SSE.</p> <p>Request:</p> <pre><code>{\n  \"method\": \"tasks/resubscribe\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (SSE Stream):</p> <pre><code>data: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 2...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\":false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 3...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": true\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\":\"2025-04-02T16:59:35.331844\"\n    },\n    \"final\": true\n  }\n}\n</code></pre>"},{"location":"documentation/#non-textual-media","title":"Non-textual Media","text":"<p>The following example demonstrates an interaction between a client and an agent involving non-textual data (a PDF file).</p> <p>Request (Sequence 1 - Send File):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Analyze the attached report and generate high level overview\"\n        },\n        {\n          \"type\": \"file\",\n          \"file\": {\n            \"mimeType\": \"application/pdf\",\n            \"data\": \"&lt;base64-encoded-content&gt;\"\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 2 - Acknowledgment/Working):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"working\",\n      \"message\": {\n        \"role\": \"agent\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"analysis in progress, please wait\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Request (Sequence 3 - Get Result):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 10,\n  \"method\": \"tasks/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 4 - Completed with Analysis):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"&lt;generated analysis content&gt;\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"documentation/#structured-output","title":"Structured Output","text":"<p>Both the client and the agent can request structured output from the other party by specifying a <code>mimeType</code> and <code>schema</code> in the <code>metadata</code> of a <code>Part</code>.</p> <p>Request (Requesting JSON Output):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Show me a list of my open IT tickets\",\n          \"metadata\": {\n            \"mimeType\": \"application/json\",\n            \"schema\": {\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                  \"ticketNumber\": { \"type\": \"string\" },\n                  \"description\": { \"type\": \"string\" }\n                }\n              }\n            }\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Providing JSON Output):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\": \"2025-04-17T17:47:09.680794\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"[{\\\"ticketNumber\\\":\\\"REQ12312\\\",\\\"description\\\":\\\"request for VPN access\\\"},{\\\"ticketNumber\\\":\\\"REQ23422\\\",\\\"description\\\":\\\"Add to DL - team-gcp-onboarding\\\"}]\"\n          }\n        ],\n        \"index\": 0\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"documentation/#error-handling","title":"Error Handling","text":"<p>Following is the <code>ErrorMessage</code> format for the server to respond to the client when it encounters an error processing the client request.</p> <pre><code>interface ErrorMessage {\n  code: number;\n  message: string;\n  data?: any;\n}\n</code></pre> <p>The following are the standard JSON-RPC error codes that the server can respond with for error scenarios:</p> Error Code Message Description <code>-32700</code> JSON parse error Invalid JSON was sent <code>-32600</code> Invalid Request Request payload validation error <code>-32601</code> Method not found Not a valid method <code>-32602</code> Invalid params Invalid method parameters <code>-32603</code> Internal error Internal JSON-RPC error <code>-32000</code> to <code>-32099</code> Server error Reserved for implementation specific error codes <code>-32001</code> Task not found Task not found with the provided id <code>-32002</code> Task cannot be canceled Task cannot be canceled by the remote agent <code>-32003</code> Push notifications not supported Push Notification is not supported by the agent <code>-32004</code> Unsupported operation Operation is not supported <code>-32005</code> Incompatible content types Incompatible content types between client and an agent"},{"location":"partners/","title":"Partners","text":"<p>Below is a list of partners (and a link to their A2A announcement or blog post, if available) who are part of the A2A community and are helping build, codify, and adopt A2A as the standard standard protocol for AI agents to communicate and collaborate effectively with each other and with users.</p> <ul> <li>Accenture</li> <li>Arize</li> <li>Articul8</li> <li>ask-ai.com</li> <li>Atlassian</li> <li>BCG</li> <li>Box</li> <li>C3 AI</li> <li>Capgemini</li> <li>Chronosphere</li> <li>Cognizant</li> <li>Cohere</li> <li>Collibra</li> <li>Contextual</li> <li>Cotality (fka Corelogic)</li> <li>Datadog</li> <li>DataRobot</li> <li>DataStax</li> <li>Decagon.ai</li> <li>Deloitte</li> <li>Devnagri</li> <li>Elastic</li> <li>Ema.co</li> <li>EPAM</li> <li>Glean</li> <li>GrowthLoop</li> <li>Harness</li> <li>HCLTech</li> <li>Incorta</li> <li>InfoSys</li> <li>Intuit</li> <li>JetBrains</li> <li>JFrog</li> <li>KPMG</li> <li>LabelBox</li> <li>LangChain</li> <li>Livex.ai</li> <li>LTIMindTtree</li> <li>Lyzr.ai</li> <li>McKinsey</li> <li>MongoDB</li> <li>Neo4j</li> <li>New Relic</li> <li>Oracle / NetSuite</li> <li>Pendo</li> <li>PWC</li> <li>Quantiphi</li> <li>S\\&amp;P</li> <li>Salesforce</li> <li>SAP</li> <li>ServiceNow</li> <li>Supertab</li> <li>TCS</li> <li>Typeface</li> <li>UKG</li> <li>Weights &amp; Biases</li> <li>Wipro</li> <li>Workday</li> <li>Writer</li> <li>Zeotap</li> </ul> <p>Note</p> <p>If you're interested in becoming a partner of A2A and getting your listing added to or updated on this page, let us know by submitting this form, and we'll contact you soon!</p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#a2a-blog-post","title":"A2A Blog Post","text":"<p>Blog Post: Announcing the Agent2Agent Protocol (A2A)</p>"},{"location":"resources/#json-specification","title":"JSON Specification","text":"<p>A2A JSON specification</p>"},{"location":"resources/#code-samples","title":"Code Samples","text":"<p>A2A Code Samples on GitHub</p>"},{"location":"specification/","title":"Agent2Agent Protocol (A2A)","text":"<p>An open protocol enabling Agent-to-Agent interoperability, bridging the gap between opaque agentic systems.</p> <p></p>"},{"location":"specification/#key-principles","title":"Key Principles","text":"<p>Using A2A, agents accomplish tasks for end users without sharing memory, thoughts, or tools. Instead the agents exchange context, status, instructions, and data in their native modalities.</p> <ul> <li>Simple: Reuse existing standards</li> <li>Enterprise Ready: Auth, Security, Privacy, Tracing, Monitoring</li> <li>Async First: (Very) Long running-tasks and human-in-the-loop</li> <li>Modality Agnostic: text, audio/video, forms, iframe, etc.</li> <li>Opaque Execution: Agents do not have to share thoughts, plans, or tools.</li> </ul>"},{"location":"specification/#more-detailed-discussions","title":"More Detailed Discussions","text":"<ul> <li>A2A and MCP</li> <li>Enterprise Ready</li> <li>Push Notifications</li> <li>Agent Discovery</li> </ul>"},{"location":"specification/agent-card/","title":"Agent Card","text":""},{"location":"specification/agent-card/#agent-card","title":"Agent Card","text":"<p>Remote Agents that support A2A are required to publish an Agent Card in JSON format describing the agent's capabilities/skills and authentication mechanism. Clients use the Agent Card information to identify the best agent that can perform a task and leverage A2A to communicate with that remote agent.</p>"},{"location":"specification/agent-card/#discovery","title":"Discovery","text":"<p>We recommend agents host their Agent Card at <code>https://DOMAIN/.well-known/agent.json</code>. This is compatible with a DNS approach where the client finds the server IP via DNS and sends an HTTP <code>GET</code> to retrieve the agent card. We also anticipate that systems will maintain private registries (e.g. an 'Agent Catalog' or private marketplace, etc). More discussion can be found in this document.</p>"},{"location":"specification/agent-card/#representation","title":"Representation","text":"<p>Following is the proposed representation of an Agent Card</p> <pre><code>// An AgentCard conveys key information:\n// - Overall details (version, name, description, uses)\n// - Skills: A set of capabilities the agent can perform\n// - Default modalities/content types supported by the agent.\n// - Authentication requirements\ninterface AgentCard {\n  // Human readable name of the agent.\n  // (e.g. \"Recipe Agent\")\n  name: string;\n  // A human-readable description of the agent. Used to assist users and\n  // other agents in understanding what the agent can do.\n  // (e.g. \"Agent that helps users with recipes and cooking.\")\n  description: string;\n  // A URL to the address the agent is hosted at.\n  url: string;\n  // The service provider of the agent\n  provider?: {\n    organization: string;\n    url: string;\n  };\n  // The version of the agent - format is up to the provider. (e.g. \"1.0.0\")\n  version: string;\n  // A URL to documentation for the agent.\n  documentationUrl?: string;\n  // Optional capabilities supported by the agent.\n  capabilities: {\n    streaming?: boolean; // true if the agent supports SSE\n    pushNotifications?: boolean; // true if the agent can notify updates to client\n    stateTransitionHistory?: boolean; //true if the agent exposes status change history for tasks\n  };\n  // Authentication requirements for the agent.\n  // Intended to match OpenAPI authentication structure.\n  authentication: {\n    schemes: string[]; // e.g. Basic, Bearer\n    credentials?: string; //credentials a client should use for private cards\n  };\n  // The set of interaction modes that the agent\n  // supports across all skills. This can be overridden per-skill.\n  defaultInputModes: string[]; // supported mime types for input\n  defaultOutputModes: string[]; // supported mime types for output\n  // Skills are a unit of capability that an agent can perform.\n  skills: {\n    id: string; // unique identifier for the agent's skill\n    name: string; //human readable name of the skill\n    // description of the skill - will be used by the client or a human\n    // as a hint to understand what the skill does.\n    description: string;\n    // Set of tag words describing classes of capabilities for this specific\n    // skill (e.g. \"cooking\", \"customer support\", \"billing\")\n    tags: string[];\n    // The set of example scenarios that the skill can perform.\n    // Will be used by the client as a hint to understand how the skill can be\n    // used. (e.g. \"I need a recipe for bread\")\n    examples?: string[]; // example prompts for tasks\n    // The set of interaction modes that the skill supports\n    // (if different than the default)\n    inputModes?: string[]; // supported mime types for input\n    outputModes?: string[]; // supported mime types for output\n  }[];\n}\n</code></pre>"},{"location":"specification/agent-to-agent-communication/","title":"Agent-to-Agent Communication","text":""},{"location":"specification/agent-to-agent-communication/#agent-to-agent-communication","title":"Agent-to-Agent Communication","text":"<p>The communication between a Client and a Remote Agent is oriented towards task completion where agents collaboratively fulfill an end user's request. A Task object allows a Client and a Remote Agent to collaborate for completing the submitted task.</p> <p>A task can be completed by a remote agent immediately or it can be long-running. For long-running tasks, the client may poll the agent for fetching the latest status. Agents can also push notifications to the client via SSE (if connected) or through an external notification service.</p>"},{"location":"specification/agent-to-agent-communication/#core-objects","title":"Core Objects","text":""},{"location":"specification/agent-to-agent-communication/#task","title":"Task","text":"<p>A Task is a stateful entity that allows Clients and Remote Agents to achieve a specific outcome and generate results. Clients and Remote Agents exchange Messages within a Task. Remote Agents generate results as Artifacts.</p> <p>A Task is always created by a Client and the status is always determined by the Remote Agent. Multiple Tasks may be part of a common session (denoted by optional sessionId) if required by the client. To do so, the Client sets an optional sessionId when creating the Task.</p> <p>The agent may:</p> <ul> <li>fulfill the request immediately</li> <li>schedule work for later</li> <li>reject the request</li> <li>negotiate a different modality</li> <li>ask the client for more information</li> <li>delegate to other agents and systems</li> </ul> <p>Even after fulfilling the goal, the client can request more information or a change in the context of that same Task. (For example client: \"draw a picture of a rabbit\", agent: \"&lt;picture&gt;\", client: \"make it red\").</p> <p>Tasks are used to transmit Artifacts (results) and Messages (thoughts, instructions, anything else). Tasks maintain a status and an optional history of status and Messages.</p> <pre><code>interface Task {\n  id: string; // unique identifier for the task\n  sessionId: string; // client-generated id for the session holding the task.\n  status: TaskStatus; // current status of the task\n  history?: Message[];\n  artifacts?: Artifact[]; // collection of artifacts created by the agent.\n  metadata?: Record&lt;string, any&gt;; // extension metadata\n}\n// TaskState and accompanying message.\ninterface TaskStatus {\n  state: TaskState;\n  message?: Message; //additional status updates for client\n  timestamp?: string; // ISO datetime value\n}\n// sent by server during sendSubscribe or subscribe requests\ninterface TaskStatusUpdateEvent {\n  id: string; //Task id\n  status: TaskStatus;\n  final: boolean; //indicates the end of the event stream\n  metadata?: Record&lt;string, any&gt;;\n}\n// sent by server during sendSubscribe or subscribe requests\ninterface TaskArtifactUpdateEvent {\n  id: string; //Task id\n  artifact: Artifact;\n  metadata?: Record&lt;string, any&gt;;\n}\n// Sent by the client to the agent to create, continue, or restart a task.\ninterface TaskSendParams {\n  id: string;\n  sessionId?: string; //server creates a new sessionId for new tasks if not set\n  message: Message;\n  historyLength?: number; //number of recent messages to be retrieved\n  // where the server should send notifications when disconnected.\n  pushNotification?: PushNotificationConfig;\n  metadata?: Record&lt;string, any&gt;; // extension metadata\n}\ntype TaskState =\n  | \"submitted\"\n  | \"working\"\n  | \"input-required\"\n  | \"completed\"\n  | \"canceled\"\n  | \"failed\"\n  | \"unknown\";\n</code></pre>"},{"location":"specification/agent-to-agent-communication/#artifact","title":"Artifact","text":"<p>Agents generate Artifacts as an end result of a Task. Artifacts are immutable, can be named, and can have multiple parts. A streaming response can append parts to existing Artifacts.</p> <p>A single Task can generate many Artifacts. For example, \"create a webpage\" could create separate HTML and image Artifacts.</p> <pre><code>interface Artifact {\n  name?: string;\n  description?: string;\n  parts: Part[];\n  metadata?: Record&lt;string, any&gt;;\n  index: number;\n  append?: boolean;\n  lastChunk?: boolean;\n}\n</code></pre>"},{"location":"specification/agent-to-agent-communication/#message","title":"Message","text":"<p>A Message contains any content that is not an Artifact. This can include things like agent thoughts, user context, instructions, errors, status, or metadata.</p> <p>All content from a client comes in the form of a Message. Agents send Messages to communicate status or to provide instructions (whereas generated results are sent as Artifacts).</p> <p>A Message can have multiple parts to denote different pieces of content. For example, a user request could include a textual description from a user and then multiple files used as context from the client.</p> <pre><code>interface Message {\n  role: \"user\" | \"agent\";\n  parts: Part[];\n  metadata?: Record&lt;string, any&gt;;\n}\n</code></pre>"},{"location":"specification/agent-to-agent-communication/#part","title":"Part","text":"<p>A fully formed piece of content exchanged between a client and a remote agent as part of a Message or an Artifact. Each Part has its own content type and metadata.</p> <pre><code>interface TextPart {\n  type: \"text\";\n  text: string;\n}\ninterface FilePart {\n  type: \"file\";\n  file: {\n    name?: string;\n    mimeType?: string;\n    // oneof {\n    bytes?: string; //base64 encoded content\n    uri?: string;\n    //}\n  };\n}\ninterface DataPart {\n  type: \"data\";\n  data: Record&lt;string, any&gt;;\n}\ntype Part = (TextPart | FilePart | DataPart) &amp; {\n  metadata: Record&lt;string, any&gt;;\n};\n</code></pre>"},{"location":"specification/agent-to-agent-communication/#push-notifications","title":"Push Notifications","text":"<p>A2A supports a secure notification mechanism whereby an agent can notify a client of an update outside of a connected session via a PushNotificationService. Within and across enterprises, it is critical that the agent verifies the identity of the notification service, authenticates itself with the service, and presents an identifier that ties the notification to the executing Task.</p> <p>The target server of the PushNotificationService should be considered a separate service, and is not guaranteed (or even expected) to be the client directly. This PushNotificationService is responsible for authenticating and authorizing the agent and for proxying the verified notification to the appropriate endpoint (which could be anything from a pub/sub queue, to an email inbox or other service, etc).</p> <p>For contrived scenarios with isolated client-agent pairs (e.g. local service mesh in a contained VPC, etc.) or isolated environments without enterprise security concerns, the client may choose to simply open a port and act as its own PushNotificationService. Any enterprise implementation will likely have a centralized service that authenticates the remote agents with trusted notification credentials and can handle online/offline scenarios. (This should be thought of similarly to a mobile Push Notification Service).</p> <pre><code>interface PushNotificationConfig {\n  url: string;\n  token?: string; // token unique to this task/session\n  authentication?: {\n    schemes: string[];\n    credentials?: string;\n  };\n}\ninterface TaskPushNotificationConfig {\n  id: string; //task id\n  pushNotificationConfig: PushNotificationConfig;\n}\n</code></pre>"},{"location":"specification/overview/","title":"Overview","text":""},{"location":"specification/overview/#overview","title":"Overview","text":""},{"location":"specification/overview/#actors","title":"Actors","text":"<p>The A2A protocol has three actors:</p> <ul> <li>User   The end user (human or service) that is using an agentic system to accomplish tasks.</li> <li>Client   The entity (service, agent, application) that is requesting an action from an opaque agent on behalf of the user.</li> <li>Remote Agent (Server)   The opaque (\"black box\") agent which is the A2A server.</li> </ul>"},{"location":"specification/overview/#transport","title":"Transport","text":"<p>The protocol leverages HTTP for transport between the client and the remote agent. Depending on the capabilities of the client and the remote agent, they may leverage SSE for supporting streaming for receiving updates from the server.</p> <p>A2A leverages JSON-RPC 2.0 as the data exchange format for communication between a Client and a Remote Agent.</p>"},{"location":"specification/overview/#async","title":"Async","text":"<p>A2A clients and servers can use standard request/response patterns and poll for updates. However, A2A also supports streaming updates through SSE (while connected) and receiving push notifications while disconnected.</p>"},{"location":"specification/overview/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>A2A models agents as enterprise applications (and can do so because A2A agents are opaque and do not share tools and resources). This quickly brings enterprise-readiness to agentic interop.</p> <p>A2A follows OpenAPI's Authentication specification for authentication. Importantly, A2A agents do not exchange identity information within the A2A protocol. Instead, they obtain materials (such as tokens) out of band and transmit materials in HTTP headers and not in A2A payloads.</p> <p>While A2A does not transmit identity in-band, servers do send authentication requirements in A2A payloads. At minimum, servers are expected to publish their requirements in their Agent Card. Thoughts about discovering agent cards are in this topic.</p> <p>Clients should use one of the servers published authentication protocols to authenticate their identity and obtain credential material. A2A servers should authenticate every request and reject or challenge requests with standard HTTP response codes (401, 403), and authentication-protocol-specific headers and bodies (such as a HTTP 401 response with a WWW-Authenticate header indicating the required authentication schema, or OIDC discovery document at a well-known path). More details discussed in Enterprise Ready.</p> <p>Note: If an agent requires that the client/user provide additional credentials during execution of a task (for example, to use a specific tool), the agent should return a task status of <code>Input-Required</code> with the payload being an Authentication structure. The client should, again, obtain credential material out of band to A2A.</p>"},{"location":"specification/sample-messages/","title":"Sample Messages","text":""},{"location":"specification/sample-messages/#sample-methods-and-json-responses","title":"Sample Methods and JSON Responses","text":""},{"location":"specification/sample-messages/#sample-agent-card","title":"Sample Agent Card","text":"<pre><code>{\n  \"name\": \"Google Maps Agent\",\n  \"description\": \"Plan routes, remember places, and generate directions\",\n  \"url\": \"https://maps-agent.google.com\",\n  \"provider\": {\n    \"organization\": \"Google\",\n    \"url\": \"https://google.com\"\n  },\n  \"version\": \"1.0.0\",\n  \"authentication\": {\n    \"schemes\": \"OAuth2\"\n  },\n  \"defaultInputModes\": [\"text/plain\"],\n  \"defaultOutputModes\": [\"text/plain\", \"application/html\"],\n  \"capabilities\": {\n    \"streaming\": true,\n    \"pushNotifications\": false\n  },\n  \"skills\": [\n    {\n      \"id\": \"route-planner\",\n      \"name\": \"Route planning\",\n      \"description\": \"Helps plan routing between two locations\",\n      \"tags\": [\"maps\", \"routing\", \"navigation\"],\n      \"examples\": [\n        \"plan my route from Sunnyvale to Mountain View\",\n        \"what's the commute time from Sunnyvale to San Francisco at 9AM\",\n        \"create turn by turn directions from Sunnyvale to Mountain View\"\n      ],\n      // can return a video of the route\n      \"outputModes\": [\"application/html\", \"video/mp4\"]\n    },\n    {\n      \"id\": \"custom-map\",\n      \"name\": \"My Map\",\n      \"description\": \"Manage a custom map with your own saved places\",\n      \"tags\": [\"custom-map\", \"saved-places\"],\n      \"examples\": [\n        \"show me my favorite restaurants on the map\",\n        \"create a visual of all places I've visited in the past year\"\n      ],\n      \"outputModes\": [\"application/html\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"specification/sample-messages/#send-a-task","title":"Send a Task","text":"<p>Allows a client to send content to a remote agent to start a new Task, resume an interrupted Task, or reopen a completed Task. A Task interrupt may be caused by an agent requiring additional user input or a runtime error.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"tell me a joke\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"name\": \"joke\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Why did the chicken cross the road? To get to the other side!\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#get-a-task","title":"Get a Task","text":"<p>Clients may use this method to retrieve the generated Artifacts for a Task. The agent determines the retention window for Tasks previously submitted to it. An agent may return an error code for Tasks that were past the retention window or for Tasks that are short-lived and not persisted.</p> <p>The client may also request the last N items of history for the Task, which will include all Messages, in order, sent by the client and server. By default, this is 0 (no history).</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"historyLength\": 10,\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Why did the chicken cross the road? To get to the other side!\"\n          }\n        ]\n      }\n    ],\n    \"history\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"tell me a joke\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#cancel-a-task","title":"Cancel a Task","text":"<p>A client may choose to cancel previously submitted Tasks.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/cancel\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"canceled\"\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#set-task-push-notifications","title":"Set Task Push Notifications","text":"<p>Clients may configure a push notification URL for receiving an update on Task status change.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/pushNotification/set\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#get-task-push-notifications","title":"Get Task Push Notifications","text":"<p>Clients may retrieve the currently configured push notification configuration for a Task using this method.</p> <p>Request:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/pushNotification/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"jwt\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#multi-turn-conversations","title":"Multi-turn Conversations","text":"<p>A Task may pause execution on the remote agent if it requires additional user input. When a Task is in the <code>input-required</code> state, the client must provide additional input for the Task to resume processing.</p> <p>The Message included in the <code>input-required</code> state must include details indicating what the client must do (e.g., \"fill out a form\", \"log into SaaS service foo\"). If this includes structured data, the instruction should be sent as one <code>Part</code> and the structured data as a second <code>Part</code>.</p> <p>Request (Sequence 1):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"request a new phone for me\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 2 - Input Required):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"input-required\",\n      \"message\": {\n        \"role\": \"agent\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"Select a phone type (iPhone/Android)\"\n          }\n        ]\n      }\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Request (Sequence 3 - Providing Input):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Android\"\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 4 - Completion):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 2,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"name\": \"order-confirmation\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"I have ordered a new Android device for you. Your request number is R12443\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#streaming-support","title":"Streaming Support","text":"<p>For clients and remote agents capable of communicating over HTTP with Server-Sent Events (SSE), clients can send the RPC request with method <code>tasks/sendSubscribe</code> when creating a new Task. The remote agent can respond with a stream of <code>TaskStatusUpdateEvents</code> (to communicate status changes or instructions/requests) and <code>TaskArtifactUpdateEvents</code> (to stream generated results).</p> <p>Note that <code>TaskArtifactUpdateEvents</code> can append new parts to existing Artifacts. Clients can use <code>tasks/get</code> to retrieve the entire Artifact outside of the streaming context. Agents must set the <code>final: true</code> attribute at the end of the stream or if the agent is interrupted and requires additional user input.</p> <p>Request:</p> <pre><code>{\n  \"method\": \"tasks/sendSubscribe\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"write a long paper describing the attached pictures\"\n        },\n        {\n          \"type\": \"file\",\n          \"file\": {\n            \"mimeType\": \"image/png\",\n            \"data\": \"&lt;base64-encoded-content&gt;\"\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (SSE Stream):</p> <pre><code>data: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"status\": {\n      \"state\": \"working\",\n      \"timestamp\":\"2025-04-02T16:59:25.331844\"\n    },\n    \"final\": false\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 1...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": false,\n      \"lastChunk\": false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 2...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": 1,\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 3...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": true\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": 1,\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\":\"2025-04-02T16:59:35.331844\"\n    },\n    \"final\": true\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#resubscribe-to-task","title":"Resubscribe to Task","text":"<p>A disconnected client may resubscribe to a remote agent that supports streaming to receive Task updates via SSE.</p> <p>Request:</p> <pre><code>{\n  \"method\": \"tasks/resubscribe\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (SSE Stream):</p> <pre><code>data: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 2...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\":false\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"artifact\": {\n      \"parts\": [\n        {\"type\":\"text\", \"text\": \"&lt;section 3...&gt;\"}\n      ],\n      \"index\": 0,\n      \"append\": true,\n      \"lastChunk\": true\n    }\n  }\n}\n\ndata: {\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\":\"2025-04-02T16:59:35.331844\"\n    },\n    \"final\": true\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#non-textual-media","title":"Non-textual Media","text":"<p>The following example demonstrates an interaction between a client and an agent involving non-textual data (a PDF file).</p> <p>Request (Sequence 1 - Send File):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Analyze the attached report and generate high level overview\"\n        },\n        {\n          \"type\": \"file\",\n          \"file\": {\n            \"mimeType\": \"application/pdf\",\n            \"data\": \"&lt;base64-encoded-content&gt;\"\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 2 - Acknowledgment/Working):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"working\",\n      \"message\": {\n        \"role\": \"agent\",\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"analysis in progress, please wait\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Request (Sequence 3 - Get Result):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 10,\n  \"method\": \"tasks/get\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Sequence 4 - Completed with Analysis):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"&lt;generated analysis content&gt;\"\n          }\n        ],\n        \"metadata\": {}\n      }\n    ],\n    \"metadata\": {}\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#structured-output","title":"Structured Output","text":"<p>Both the client and the agent can request structured output from the other party by specifying a <code>mimeType</code> and <code>schema</code> in the <code>metadata</code> of a <code>Part</code>.</p> <p>Request (Requesting JSON Output):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"method\": \"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"message\": {\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Show me a list of my open IT tickets\",\n          \"metadata\": {\n            \"mimeType\": \"application/json\",\n            \"schema\": {\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                  \"ticketNumber\": { \"type\": \"string\" },\n                  \"description\": { \"type\": \"string\" }\n                }\n              }\n            }\n          }\n        }\n      ]\n    },\n    \"metadata\": {}\n  }\n}\n</code></pre> <p>Response (Providing JSON Output):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 9,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\",\n      \"timestamp\": \"2025-04-17T17:47:09.680794\"\n    },\n    \"artifacts\": [\n      {\n        \"parts\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"[{\\\"ticketNumber\\\":\\\"REQ12312\\\",\\\"description\\\":\\\"request for VPN access\\\"},{\\\"ticketNumber\\\":\\\"REQ23422\\\",\\\"description\\\":\\\"Add to DL - team-gcp-onboarding\\\"}]\"\n          }\n        ],\n        \"index\": 0\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"specification/sample-messages/#error-handling","title":"Error Handling","text":"<p>Following is the <code>ErrorMessage</code> format for the server to respond to the client when it encounters an error processing the client request.</p> <pre><code>interface ErrorMessage {\n  code: number;\n  message: string;\n  data?: any;\n}\n</code></pre> <p>The following are the standard JSON-RPC error codes that the server can respond with for error scenarios:</p> Error Code Message Description <code>-32700</code> JSON parse error Invalid JSON was sent <code>-32600</code> Invalid Request Request payload validation error <code>-32601</code> Method not found Not a valid method <code>-32602</code> Invalid params Invalid method parameters <code>-32603</code> Internal error Internal JSON-RPC error <code>-32000</code> to <code>-32099</code> Server error Reserved for implementation specific error codes <code>-32001</code> Task not found Task not found with the provided id <code>-32002</code> Task cannot be canceled Task cannot be canceled by the remote agent <code>-32003</code> Push notifications not supported Push Notification is not supported by the agent <code>-32004</code> Unsupported operation Operation is not supported <code>-32005</code> Incompatible content types Incompatible content types between client and an agent"},{"location":"topics/a2a-and-mcp/","title":"Using Agent-to-Agent with MCP","text":""},{"location":"topics/a2a-and-mcp/#a2a-mcp","title":"A2A \u2764\ufe0f MCP","text":"<p>TL;DR; Agentic applications need both A2A and MCP. We recommend MCP for tools and A2A for agents.</p>"},{"location":"topics/a2a-and-mcp/#why-protocols","title":"Why Protocols?","text":"<p>Standard protocols are essential for enabling agentic interoperability, particularly in connecting agents to external systems. This is critical in two interconnected areas of innovation: Tools and Agents.</p> <p>Tools are primitives with structured inputs and outputs and (typically) well-known behavior. Agents are autonomous applications that can accomplish novel tasks by using tools, reasoning, and user interactions. Agentic applications must use both tools and agents to accomplish goals for their users.</p>"},{"location":"topics/a2a-and-mcp/#complementary","title":"Complementary","text":"<p>Model Context Protocol (MCP) is the emerging standard for connecting LLMs with data, resources, and tools. We already observe MCP standardizing 'function calling' across different models and frameworks. This is creating an ecosystem of tool service providers and dramatically lowering the complexity to connect agents with tools and data. We expect this trend to continue as more frameworks, service providers, and platforms adopt MCP.</p> <p>A2A is focused on a different problem. A2A is an application level protocol that enables agents to collaborate in their natural modalities. It allows agents to communicate as agents (or as users) instead of as tools. We hope that A2A gains adoption as a complement to MCP that enables ecosystems of agents and will be working in the open with the community to make this happen.</p>"},{"location":"topics/a2a-and-mcp/#example","title":"Example","text":"<p>Let's look at an example:</p> <p>Consider an auto repair shop that fixes cars. The shop employs autonomous workers who use special-purpose tools (such as vehicle jacks, multimeters, and socket wrenches) to diagnose and repair problems. The workers often have to diagnose and repair problems they have not seen before. The repair process can involve extensive conversations with a customer, research, and working with part suppliers.</p> <p>Now let's model the shop employees as AI agents:</p> <ul> <li> <p>MCP is the protocol to connect these agents with their structured tools (e.g. <code>raise platform by 2 meters</code>, <code>turn wrench 4 mm to the right</code>).</p> </li> <li> <p>A2A is the protocol that enables end users or other agents to work with the shop employees (\"my car is making a rattling noise\"). A2A enables ongoing back-and-forth communication and an evolving plan to achieve results (\"send me a picture of the left wheel\", \"I notice fluid leaking. How long has that been happening?\"). A2A also helps the auto shop employees work with other agents such as their part suppliers.</p> </li> </ul>"},{"location":"topics/a2a-and-mcp/#intersection","title":"Intersection","text":"<p>We recommend that applications model A2A agents as MCP resources (represented by their AgentCard). The frameworks can then use A2A to communicate with their user, the remote agents, and other agents.</p> <p></p>"},{"location":"topics/agent-discovery/","title":"Discovering Agent Card(s)","text":"<ul> <li>Discovering Agent Card(s)</li> <li>Open Discovery</li> <li>Curated Discovery (Registry-Based)</li> <li>Private Discovery (API-Based)</li> <li>Securing Agent Cards</li> </ul> <p>A2A's Agent Card standardizes the format of the data shared during discovery. However there are unlimited ways to discover these Agent Cards. We anticipate this being an open topic for discussion and look forward to ideas from the community.</p> <p>Here is our current thinking.</p>"},{"location":"topics/agent-discovery/#open-discovery","title":"Open Discovery","text":"<p>We recommend enterprises host their agent cards at a well-known path. Specifically: <code>https://DOMAIN/.well-known/agent.json</code>. Clients will use DNS to resolve a known or found domain, send a simple <code>GET</code> request to the path, and receive the agent card.</p> <p>This will enable web-crawlers and applications to easily discover agents for known or configured domains. This effectively reduces the discovery process to \"find a domain\".</p>"},{"location":"topics/agent-discovery/#curated-discovery-registry-based","title":"Curated Discovery (Registry-Based)","text":"<p>We anticipate enterprise applications making curated registries of agents available through a catalog interface. This opens up more enterprise scenarios such as company-specific or team-specific agent registries that are curated by an administrator.</p> <p>We are considering adding Registry support to the protocol - please drop us a note with your opinion and where you see this being valuable as a standard</p>"},{"location":"topics/agent-discovery/#private-discovery-api-based","title":"Private Discovery (API-Based)","text":"<p>There will undoubtably be private \"agent stores\" or proprietary agents where cards are exchanged behind custom APIs.</p> <p>We are not considering private discovery APIs as an A2A concern - please drop us a note with your opinion and where you see this being valuable as a standard</p>"},{"location":"topics/agent-discovery/#securing-agent-cards","title":"Securing Agent Cards","text":"<p>Agent cards may contain sensitive information. Implementors may decide to secure their agent cards behind controls that require authentication and authorization. For example, within an organization, even an open discovery at a well-known path could be guarded by mTLS and restricted to specific clients. Registries and Private Discovery APIs should require authentication and return different artifacts for different identities.</p> <p>Note that implementors may include credential information (such as API Keys) in their Agent Cards. It is recommended that this information is NEVER available without Authentication.</p>"},{"location":"topics/enterprise-ready/","title":"Enterprise Readiness","text":"<ul> <li>Enterprise Readiness</li> <li>Transport Level Security</li> <li>Server Identity</li> <li>Client and User Identity</li> <li>Authenticating Clients</li> <li>Authorization and Data Privacy</li> <li>Tracing and Observability</li> </ul> <p>A2A does not want to invent any new standards for enterprise security and instead seamlessly integrate with existing infrastructure.</p> <p>A2A models Enterprise Agents as standard, HTTP-based, enterprise applications and therefore relies on enterprise-standard auth, security, privacy, tracing, and monitoring. This is possible because A2A agents are opaque and do not share tools or resources (and therefore \"single application\" client/server best practices apply).</p> <p>In fact, A2A keeps most enterprise concerns out of the protocol and instead require enterprise-grade HTTP with Open Authentication and Open Tracing support. Implementers should follow all enterprise best practices as it relates to application and user-level security.</p>"},{"location":"topics/enterprise-ready/#transport-level-security","title":"Transport Level Security","text":"<p>A2A is built on HTTP and any production installation should require HTTPS using modern TLS ciphers.</p>"},{"location":"topics/enterprise-ready/#server-identity","title":"Server Identity","text":"<p>A2A Servers present their identity in the form of digital certificates signed by well-known certificate authorities as part of the TLS negotiation. A2A Clients should verify server identity during connection establishment.</p>"},{"location":"topics/enterprise-ready/#client-and-user-identity","title":"Client and User Identity","text":"<p>There is no concept of a user or client identifier in A2A schemas. Instead, A2A conveys authentication requirements (scheme and materials) through the protocol. The client is responsible for negotiating with the appropriate authentication authority (out of band to A2A) and retrieving/storing credential materials (such as OAuth tokens). Those credential materials will be transmitted in HTTP headers and not in any A2A payload.</p> <p>Different authentication protocols and service providers have different requirements and individual requests may require multiple identifiers and identities in scheme specific headers. It is recommended that clients always present a client identity (representing the client agent) and user identity (representing their user) in requests to A2A servers.</p> <p>Note: Multi-identity federation is an open topic for discussion. For example, User U is working with Agent A requiring A-system's identifier. If Agent A then depends on Tool B or Agent B which requires B-system identifier, the user may need to provide identities for both A-system and B-system in a single request. (Assume A-system is an enterprise LDAP identity and B-system is a SaaS-provider identity).</p> <p>It is currently recommended that if Agent A requires the user/client to provide an alternate identity for part of a task, it sends an update in the <code>INPUT-REQUIRED</code> state with the specific authentication requirements (in the same structure as an AgentCard's authentication requirements) to the client. The client then, out of band to A2A and also out of band to A-system, negotiates with B-system's authority to obtain credential material. Those materials (such as tokens) can be passed through Agent A to Agent B. Agent B will exchange when speaking to its upstream systems.</p>"},{"location":"topics/enterprise-ready/#authenticating-clients","title":"Authenticating Clients","text":"<p>A2A servers are expected to publish supported and required authentication protocol(s) in its Agent Card. These protocols should be one of the standard OpenAPI Authentication formats (such as API Keys, OAuth, OIDC, etc) but can be extended to another protocol supported by both client and server.</p> <p>Individual authentication protocols have their own mechanisms for acquiring, refreshing, and challenging credential material (such as bearer or session tokens). The credential acquisition and maintenance process is considered external to A2A.</p> <p>A2A servers are expected to authenticate every request and reject or challenge requests with standard HTTP response codes (401, 403), and authentication-protocol-specific headers and bodies (such as a HTTP 401 response with a WWW-Authenticate header indicating the required authentication schema, or OIDC discovery document at a well-known path).</p>"},{"location":"topics/enterprise-ready/#authorization-and-data-privacy","title":"Authorization and Data Privacy","text":"<p>A2A servers are expected to authorize requests based on both the user and application identity. We recommend that individual agents manage access on at least two axes:</p> <ul> <li> <p>Skills   Agents are expected to advertise (via an Agent Card) their capabilities in the form of skills. It is recommended that agents authorize on a per-skill basis (for example, OAuthScope 'foo-read-only' could limit access only to 'generateRecipe' skills).</p> </li> <li> <p>Tools (Actions and Data)   It is recommended that Agents restrict access to sensitive data or actions by placing them behind Tools. When an agentic flow or model needs to access this data, the agent should authorize access to a tool based on the application+user priviledge. We highly recommend utilizing API Management with Tool access.</p> </li> </ul>"},{"location":"topics/enterprise-ready/#tracing-and-observability","title":"Tracing and Observability","text":"<p>As all A2A requests are 'standard' HTTP requests, both client and server should use their enterprise standard tooling and infrastructure which ideally adds appropriate instrumentation headers and writes events to standard logs and event queues.</p>"},{"location":"topics/push-notifications/","title":"Remote Agent to Client Updates","text":"<ul> <li>Remote Agent to Client Updates</li> <li>Connected</li> <li>Disconnected</li> <li>Setting Task Notifications</li> <li>Agent Security</li> <li>Notification Receiver Security<ul> <li>Asymmetric keys</li> <li>Symmetric keys</li> <li>OAuth</li> <li>Bearer Token</li> </ul> </li> <li>Other Considerations<ul> <li>Replay Prevention</li> <li>Key Rotation</li> </ul> </li> </ul> <p>Some tasks can take more than seconds. They can take minutes, or hours, or even days (\"ship a sample to my client in Florida and notify me when it arrives\"). A2A agents need to communicate over long periods of time. This includes while they are connected and not connected.</p> <p>Clients can check whether an agent supports streaming and pushNotifications capability in the agent card.</p> <pre>\n{\n  \"name\": \"your-agent-name\",\n  \"description\": \"your-agent-description\"\n  ...\n\n  \"capabilities\": {\n    \"streaming\": true,\n    \"pushNotifications\": false,\n    \"stateTransitionHistory\": false\n  }\n\n  ...\n}\n</pre> <p>The agent can use below methods to get updates about task execution:</p> <ol> <li> <p>Persistent Connection: Clients can establish a persistent connection with the agent using HTTP + Server-sent events. The agent can then send task updates using those connections per client.</p> </li> <li> <p>Push Notifications: Agents can send the latest full Task object payload to client specified push notification URL. This is similar to webhooks on some platforms.</p> </li> </ol> <p>Clients can set notifications for their tasks whether they have subscribed to a Task or not. Agents should send a notification when Agent has processed a task to a stopping state like \"completed\", \"input-required\" etc and fully generated state associated message and artifacts.</p> <p>Clients can set notification info for their tasks whether they have subscribed to a Task or not. Agents should send a notification when Agent sees it appropriate to notify the client. One paradigm could be to send a notification when agent has processed a task to a stopping state like \"completed\", \"input-required\" etc and fully generated state associated message and artifacts.</p>"},{"location":"topics/push-notifications/#connected","title":"Connected","text":"<p>While connected, Agents update each other with Task (and related) messages. Clients and Remote Agents can work on multiple tasks concurrently over the same connection.</p> <p>Clients use Task/Send to update a current task with more information or reply to an agent need. Remote Agents reply with Task Updates while streaming or Task while not streaming. While not streaming, it is acceptable to poll at reasonable intervals.</p> <p>If the agents become disconnected, they can resume the connection and receive live updates via the Task/Resubscribe method.</p>"},{"location":"topics/push-notifications/#disconnected","title":"Disconnected","text":"<p>For disconnected scenarios, A2A supports a push notification mechanism whereby an Agent can notify a Client of an update outside of a connected session via a PushNotificationConfig. Within and across enterprises, it is critical that the agent verifies the identity of the notification service, authenticates itself with the service, and presents an identifier that ties the notification to the executing task.</p> <p>The NotificationService should be considered a separate service from the client agent, and it is not guaranteed or even expected to be the client directly. This NotificationService is responsible for authenticating and authorizing the agent and for proxying the verified notification to the appropriate endpoint (which could be anything from a pub/sub queue, to an email inbox, to another notification service, etc).</p> <p>For contrived scenarios with isolated client-agent pairs (e.g. local service mesh in a contained VPC, etc.), the client may choose to simply open a port and act as its own NotificationService. However, any enterprise implementation is recommended to have a centralized service that authenticates the remote agents with trusted notification credentials and can handle online/offline scenarios. This can be thought of similarly to a mobile Push Notification Service with its own Authentication and Authorization controls.</p>"},{"location":"topics/push-notifications/#setting-task-notifications","title":"Setting Task Notifications","text":"<p>Clients need to set task push notification config to asynchronously receive task updates. They should generate a taskId and set the push notification configuration for the same using \"tasks/pushNotification/set\" RPC or directly in the <code>pushNotification</code> param of \"tasks/send\", \"tasks/sendSubscribe\".</p> <pre>\ninterface PushNotificationConfig {\n  url: string;\n  token?: string; // token unique to this task/session\n  authentication?: {\n    schemes: string[];\n    credentials?: string;\n  }\n}\n\ninterface TaskPushNotificationConfig {\n  id: string; //task id\n  pushNotificationConfig: PushNotificationConfig;\n}\n\n// Request to send to a task (with push notification configuration)\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\":\"tasks/send\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",    \n    \"message\": {\n      \"role\":\"user\",\n      \"parts\": [{\n        \"type\":\"text\",\n        \"text\": \"tell me a joke\"\n      }]   \n    },\n    \"pushNotification\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"bearer\"]\n      }\n    },\n    \"metadata\": {}\n  }\n}\n\n//response\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",\n    \"sessionId\": \"c295ea44-7543-4f78-b524-7a38915ad6e4\",\n    \"status\": {\n      \"state\": \"completed\",\n    },\n    \"artifacts\": [{\n      \"name\":\"joke\",\n      \"parts\": [{\n          \"type\":\"text\",\n          \"text\":\"Why did the chicken cross the road? To get to the other side!\"\n        }]\n      }],    \n    \"metadata\": {}\n  }\n}\n\n// Request to set push notification config\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\":\"tasks/pushNotification/set\",\n  \"params\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",    \n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"bearer\"]\n      }\n    }\n  }\n}\n\n//Response\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"id\": \"de38c76d-d54c-436c-8b9f-4c2703648d64\",    \n    \"pushNotificationConfig\": {\n      \"url\": \"https://example.com/callback\",\n      \"authentication\": {\n        \"schemes\": [\"bearer\"]\n      }\n    }\n  }\n}\n</pre>"},{"location":"topics/push-notifications/#agent-security","title":"Agent Security","text":"<p>Agents should not blindly trust the push notification URL specified by the client. Some commonly used practices are as below:</p> <ol> <li> <p>They should verify the push notification URL by issuing a GET challenge request.</p> </li> <li> <p>The challenge request can be the same push notification URL but with a validationToken provided either as a URL query param or a header.</p> </li> <li>The notification service (or the client in simple cases) should respond to challenge request by returning the same validationToken.</li> <li>This seems simple but it helps avoid tricking remote agent into DDoS-ing a URL by a malicious client.</li> <li>Agents can issue this challenge request one-time when the push notification URL is registered or keep checking this URL periodically.   <pre>\n   GET https://abc.com/callback-path?validationToken=randomString\n   Content-Length: 0\n\n   HTTP/1.1 200 OK\n   Content-Type: text/plain\n\n   randomString\n   </pre> </li> </ol> <p>An example of such check has been added in method <code>set_push_notification_info</code> of LangGraph and CLI Push listener</p> <ol> <li>To further verify the identity of the notification service, it can be asked to sign the above validationToken using a pre-determined secret.</li> <li>The secret could be generated by the agent, specifically for this challenge request.</li> <li>Or if the notification service and agent use a symmetric shared key for authentication, the same key can be used by notification service to sign the validationToken.</li> </ol>"},{"location":"topics/push-notifications/#notification-receiver-security","title":"Notification Receiver Security","text":"<p>Notification Receivers should check the authenticity of the notifications they are receiving. A few ways they can do that are described as follows. Also, a collection of ideas for notification security can be found at https://webhooks.fyi</p> <p>An example of push notifications using JWT + JWKS using asymmetric keys has been added in LangGraph and CLI Host</p>"},{"location":"topics/push-notifications/#asymmetric-keys","title":"Asymmetric keys","text":"<p>A pair of private and public keys can be generated using ECDSA, RSA etc. These can be generated by the notification server or the remote agent.</p> <ol> <li>If the key pair is generated by the notification server, (ex. APNS), the private key needs to be supplied to the agent. The notification server should keep the public key to verify incoming request payloads signed by the agent using the private key.</li> <li>If the key pair is generated by the agent. Then there can be two options:</li> <li>The public key is manually provided to the Notification Receiver.</li> <li>Or the public keys can be provided by the agent through JWKS protocol.</li> </ol> <p>Agents can sign request payload using the private key and provide the request signature as a header. Or they can use JWT protocol to generate a token and provide that as a signature. Benefit of JWT protocol would also be that it standardises common fields like keyId, request timestamp.</p>"},{"location":"topics/push-notifications/#symmetric-keys","title":"Symmetric keys","text":"<p>A simpler method can be that both notification server and agents use the same shared key to sign and verify. The notification server verifies the signature by re-signing the payload with the key. Again JWT can be used to generate the signature token.</p> <p>Asymmetric keys have an advantage as only the agent knows the public key and hence less chances of the key being leaked.</p>"},{"location":"topics/push-notifications/#oauth","title":"OAuth","text":"<p>Agent gets an auth token from OAuth server and supplies that in the push notification request, either as a header or as part of request payload. Notification server extracts the OAuth token and verifies it from the OAuth server.</p>"},{"location":"topics/push-notifications/#bearer-token","title":"Bearer Token","text":"<p>Either party can generate the bearer token. If generated by the Notification Receiver, it can provide this token to the remote agent through the task push notification configuration.</p> <p>Since this is part of a request in plain-text, this has a chance of being leaked and hence malicious request payloads can be sent with this token. With asymmetric or symmetric keys, the payload was signed, which allowed Notification Receivers to verify authenticity of request payloads.</p>"},{"location":"topics/push-notifications/#other-considerations","title":"Other Considerations","text":""},{"location":"topics/push-notifications/#replay-prevention","title":"Replay Prevention","text":"<p>Use <code>iat</code> in JWT or other header to describe the event timestamp. Ideally any event older than 5 mins should be rejected. This provides some protection from replay attacks. The timestamp should also be part of the overall request data which is fed into calculation of request signature. This validates the authenticity of timestamps as well.</p>"},{"location":"topics/push-notifications/#key-rotation","title":"Key Rotation","text":"<p>Ideally agents should implement a key rotation with zero downtime. One way to do this is JWKS, it allows agents to publish their public keys, both old and new. Notification Receivers should be able to use both the keys to validate the notification request payload.</p>"},{"location":"tutorials/python/1-introduction/","title":"A2A Python Quickstart Tutorial","text":"<p>In this tutorial, you will build a simple echo A2A server using Python. This barebones implementation will show you all the features A2A has to offer. Following this tutorial, you will be able to add agent functionality using Ollama or Google's Agent Development Kit</p>"},{"location":"tutorials/python/1-introduction/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>[x] The basic concepts behind A2A</li> <li>[x] How to create an A2A server in Python</li> <li>[x] Interacting with an A2A server</li> <li>[x] Add a trained model to act as the agent</li> </ul> Next"},{"location":"tutorials/python/10-next-steps/","title":"Next Steps","text":"<p>Congratulations! You now have mastered the basics of running an A2A server with an AI model as the agent. Here's some ideas of where to go next.</p> <ul> <li>Connect our AI model with [MCP tools]</li> <li>Hint: first create a MCP Server</li> <li>Then: Integrate MCP Tools into our existing call to <code>create_react_agent(ollama_chat_llm, tools=[])</code></li> <li>Develop your own agent using Google's Agent Development Kit or other framework. Check out the samples</li> <li>\ud83d\udcda Read the A2A technical documentation to understand the capabilities</li> <li>\ud83d\udcdd Review the A2A json specification of the protocol structures</li> <li>\ud83d\udcd1 Review key topics to understand protocol details</li> <li>A2A and MCP</li> <li>Agent Discovery</li> <li>Enterprise Ready</li> <li>Push Notifications</li> </ul> Back"},{"location":"tutorials/python/2-setup/","title":"Set up Your Environment","text":""},{"location":"tutorials/python/2-setup/#what-youll-need","title":"What You'll Need","text":"<ul> <li>A code editor such as Visual Studio Code (VS Code)</li> <li>A command prompt such as Terminal (Linux), iTerm (Mac) or just the Terminal in VS Code</li> </ul>"},{"location":"tutorials/python/2-setup/#python-environment","title":"Python Environment","text":"<p>We'll be using https://docs.astral.sh/uv/ as our package manager and to set up our project.</p> <p>The A2A libraries we'll be using require <code>python &gt;= 3.12</code> which uv can install if you don't already have a matching version. We'll be using python 3.12.</p>"},{"location":"tutorials/python/2-setup/#check","title":"Check","text":"<p>Run the following command to make sure you're ready for the next step.</p> <pre><code>echo 'import sys; print(sys.version)' | uv run -\n</code></pre> <p>If you see something similar to the following, you are ready to proceed!</p> <pre><code>3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]\n</code></pre> Back Next"},{"location":"tutorials/python/3-create-project/","title":"Creating A Project","text":"<p>Let's first create a project using <code>uv</code>. We'll add the <code>--package</code> flag in case you want to add tests, or publish your project later</p> <pre><code>uv init --package my-project\ncd my-project\n</code></pre>"},{"location":"tutorials/python/3-create-project/#using-a-virtual-env","title":"Using a Virtual Env","text":"<p>We'll create a venv for this project. This only needs to be done once</p> <pre><code>uv venv .venv\n</code></pre> <p>For this and any future terminal windows you open, you'll need to source this venv</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>If you're using a code editor such as VS Code, you'll want to set the Python Interpreter for code completions. In VS Code, press <code>Ctrl-Shift-P</code> and select <code>Python: Select Interpreter</code>. Then select your project <code>my-project</code> followed by the correct python interpreter <code>Python 3.12.3 ('.venv':venv) ./.venv/bin/python</code></p> <p>The source code should now look similar to this.</p> <pre><code>tree .\n.\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 my-project\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n</code></pre>"},{"location":"tutorials/python/3-create-project/#adding-the-google-a2a-python-libraries","title":"Adding the Google-A2A Python Libraries","text":"<p>Next we'll add the sample A2A python libraries from Google.</p> <pre><code>uv add git+https://github.com/google/A2A#subdirectory=samples/python\n</code></pre>"},{"location":"tutorials/python/3-create-project/#setting-up-the-project-structure","title":"Setting up the project structure","text":"<p>Let's now create some files we'll later be using</p> <pre><code>touch src/my_project/agent.py\ntouch src/my_project/task_manager.py\n</code></pre>"},{"location":"tutorials/python/3-create-project/#test-run","title":"Test Run","text":"<p>If everything is setup correctly, you should now be able to run your application.</p> <pre><code>uv run my-project\n</code></pre> <p>The output should look something like this.</p> <pre><code>Hello from my-project!\n</code></pre> Back Next"},{"location":"tutorials/python/4-agent-skills/","title":"Agent Skills","text":"<p>An agent skill is a set of capabilities the agent can perform. Here's an example of what it would look like for our echo agent.</p> <pre><code>{\n  id: \"my-project-echo-skill\"\n  name: \"Echo Tool\",\n  description: \"Echos the input given\",\n  tags: [\"echo\", \"repeater\"],\n  examples: [\"I will see this echoed back to me\"],\n  inputModes: [\"text\"],\n  outputModes: [\"text\"]\n}\n</code></pre> <p>This conforms to the skills section of the Agent Card</p> <pre><code>{\n  id: string; // unique identifier for the agent's skill\n  name: string; //human readable name of the skill\n  // description of the skill - will be used by the client or a human\n  // as a hint to understand what the skill does.\n  description: string;\n  // Set of tag words describing classes of capabilities for this specific\n  // skill (e.g. \"cooking\", \"customer support\", \"billing\")\n  tags: string[];\n  // The set of example scenarios that the skill can perform.\n  // Will be used by the client as a hint to understand how the skill can be\n  // used. (e.g. \"I need a recipe for bread\")\n  examples?: string[]; // example prompts for tasks\n  // The set of interaction modes that the skill supports\n  // (if different than the default)\n  inputModes?: string[]; // supported mime types for input\n  outputModes?: string[]; // supported mime types for output\n}\n</code></pre>"},{"location":"tutorials/python/4-agent-skills/#implementation","title":"Implementation","text":"<p>Let's create this Agent Skill in code. Open up <code>src/my-project/__init__.py</code> and replace the contents with the following code</p> <pre><code>import google_a2a\nfrom google_a2a.common.types import AgentSkill\n\ndef main():\n  skill = AgentSkill(\n    id=\"my-project-echo-skill\",\n    name=\"Echo Tool\",\n    description=\"Echos the input given\",\n    tags=[\"echo\", \"repeater\"],\n    examples=[\"I will see this echoed back to me\"],\n    inputModes=[\"text\"],\n    outputModes=[\"text\"],\n  )\n  print(skill)\n\nif __name__ == \"__main__\":\n  main()\n</code></pre>"},{"location":"tutorials/python/4-agent-skills/#test-run","title":"Test Run","text":"<p>Let's give this a run.</p> <pre><code>uv run my-project\n</code></pre> <p>The output should look something like this.</p> <pre><code>id='my-project-echo-skill' name='Echo Tool' description='Echos the input given' tags=['echo', 'repeater'] examples=['I will see this echoed back to me'] inputModes=['text'] outputModes=['text']\n</code></pre> Back Next"},{"location":"tutorials/python/5-add-agent-card/","title":"Agent Card","text":"<p>Now that we have defined our skills, we can create an Agent Card.</p> <p>Remote Agents are required to publish an Agent Card in JSON format describing the agent's capabilities and skills in addition to authentication mechanisms. In other words, this lets the world know about your agent and how to interact with it. You can find more details in the documentation.</p>"},{"location":"tutorials/python/5-add-agent-card/#implementation","title":"Implementation","text":"<p>First lets add some helpers for parsing command line arguments. This will be helpful later for starting our server</p> <pre><code>uv add click\n</code></pre> <p>And update our code</p> <pre><code>import logging\n\nimport click\nfrom dotenv import load_dotenv\nimport google_a2a\nfrom google_a2a.common.types import AgentSkill, AgentCapabilities, AgentCard\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@click.command()\n@click.option(\"--host\", default=\"localhost\")\n@click.option(\"--port\", default=10002)\ndef main(host, port):\n  skill = AgentSkill(\n    id=\"my-project-echo-skill\",\n    name=\"Echo Tool\",\n    description=\"Echos the input given\",\n    tags=[\"echo\", \"repeater\"],\n    examples=[\"I will see this echoed back to me\"],\n    inputModes=[\"text\"],\n    outputModes=[\"text\"],\n  )\n  logging.info(skill)\n\nif __name__ == \"__main__\":\n  main()\n</code></pre> <p>Next we'll add our Agent Card</p> <pre><code># ...\ndef main(host, port):\n  # ...\n  capabilities = AgentCapabilities()\n  agent_card = AgentCard(\n    name=\"Echo Agent\",\n    description=\"This agent echos the input given\",\n    url=f\"http://{host}:{port}/\",\n    version=\"0.1.0\",\n    defaultInputModes=[\"text\"],\n    defaultOutputModes=[\"text\"],\n    capabilities=capabilities,\n    skills=[skill]\n  )\n  logging.info(agent_card)\n\nif __name__ == \"__main__\":\n  main()\n</code></pre>"},{"location":"tutorials/python/5-add-agent-card/#test-run","title":"Test Run","text":"<p>Let's give this a run.</p> <pre><code>uv run my-project\n</code></pre> <p>The output should look something like this.</p> <pre><code>INFO:root:name='Echo Agent' description='This agent echos the input given' url='http://localhost:10002/' provider=None version='0.1.0' documentationUrl=None capabilities=AgentCapabilities(streaming=False, pushNotifications=False, stateTransitionHistory=False) authentication=None defaultInputModes=['text'] defaultOutputModes=['text'] skills=[AgentSkill(id='my-project-echo-skill', name='Echo Tool', description='Echos the input given', tags=['echo', 'repeater'], examples=['I will see this echoed back to me'], inputModes=['text'], outputModes=['text'])]\n</code></pre> Back Next"},{"location":"tutorials/python/6-start-server/","title":"A2A Server","text":"<p>We're almost ready to start our server! We'll be using the <code>A2AServer</code> class from <code>Google-A2A</code> which under the hood starts a uvicorn server. However in the future this may change as <code>Google-A2A</code> is still in development.</p>"},{"location":"tutorials/python/6-start-server/#task-manager","title":"Task Manager","text":"<p>Before we create our server, we need a task manager to handle incoming requests.</p> <p>We'll be implementing the InMemoryTaskManager interface which requires us to implement two methods</p> <pre><code>async def on_send_task(\n  self,\n  request: SendTaskRequest\n) -&gt; SendTaskResponse:\n  \"\"\"\n  This method queries or creates a task for the agent.\n  The caller will receive exactly one response.\n  \"\"\"\n  pass\n\nasync def on_send_task_subscribe(\n  self,\n  request: SendTaskStreamingRequest\n) -&gt; AsyncIterable[SendTaskStreamingResponse] | JSONRPCResponse:\n  \"\"\"\n  This method subscribes the caller to future updates regarding a task.\n  The caller will receive a response and additionally receive subscription\n  updates over a session established between the client and the server\n  \"\"\"\n  pass\n</code></pre> <p>Open up <code>src/my_project/task_manager.py</code> and add the following code. We will simply returns a direct echo response and immediately mark the task complete without any sessions or subscriptions</p> <pre><code>from typing import AsyncIterable\n\nimport google_a2a\nfrom google_a2a.common.server.task_manager import InMemoryTaskManager\nfrom google_a2a.common.types import (\n  Artifact,\n  JSONRPCResponse,\n  Message,\n  SendTaskRequest,\n  SendTaskResponse,\n  SendTaskStreamingRequest,\n  SendTaskStreamingResponse,\n  Task,\n  TaskState,\n  TaskStatus,\n  TaskStatusUpdateEvent,\n)\n\nclass MyAgentTaskManager(InMemoryTaskManager):\n  def __init__(self):\n    super().__init__()\n\n  async def on_send_task(self, request: SendTaskRequest) -&gt; SendTaskResponse:\n    # Upsert a task stored by InMemoryTaskManager\n    await self.upsert_task(request.params)\n\n    task_id = request.params.id\n    # Our custom logic that simply marks the task as complete\n    # and returns the echo text\n    received_text = request.params.message.parts[0].text\n    task = await self._update_task(\n      task_id=task_id,\n      task_state=TaskState.COMPLETED,\n      response_text=f\"on_send_task received: {received_text}\"\n    )\n\n    # Send the response\n    return SendTaskResponse(id=request.id, result=task)\n\n  async def on_send_task_subscribe(\n    self,\n    request: SendTaskStreamingRequest\n  ) -&gt; AsyncIterable[SendTaskStreamingResponse] | JSONRPCResponse:\n    pass\n\n  async def _update_task(\n    self,\n    task_id: str,\n    task_state: TaskState,\n    response_text: str,\n  ) -&gt; Task:\n    task = self.tasks[task_id]\n    agent_response_parts = [\n      {\n        \"type\": \"text\",\n        \"text\": response_text,\n      }\n    ]\n    task.status = TaskStatus(\n      state=task_state,\n      message=Message(\n        role=\"agent\",\n        parts=agent_response_parts,\n      )\n    )\n    task.artifacts = [\n      Artifact(\n        parts=agent_response_parts,\n      )\n    ]\n    return task\n</code></pre>"},{"location":"tutorials/python/6-start-server/#a2a-server_1","title":"A2A Server","text":"<p>With a task manager complete, we can now create our server</p> <p>Open up <code>src/my_project/__init__.py</code> and add the following code.</p> <pre><code># ...\nfrom google_a2a.common.server import A2AServer\nfrom my_project.task_manager import MyAgentTaskManager\n# ...\ndef main(host, port):\n  # ...\n\n  task_manager = MyAgentTaskManager()\n  server = A2AServer(\n    agent_card=agent_card,\n    task_manager=task_manager,\n    host=host,\n    port=port,\n  )\n  server.start()\n</code></pre>"},{"location":"tutorials/python/6-start-server/#test-run","title":"Test Run","text":"<p>Let's give this a run.</p> <pre><code>uv run my-project\n</code></pre> <p>The output should look something like this.</p> <pre><code>INFO:     Started server process [20506]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:10002 (Press CTRL+C to quit)\n</code></pre> <p>Congratulations! Your A2A server is now running!</p> Back Next"},{"location":"tutorials/python/7-interact-with-server/","title":"Interacting With Your A2A Server","text":"<p>First we'll use Google-A2A's command-line tool to send requests to our A2A server. After trying it out, we'll write our own basic client to see how this works under the hood</p>"},{"location":"tutorials/python/7-interact-with-server/#using-google-a2as-command-line-tool","title":"Using Google-A2A's command-line tool","text":"<p>With your A2A server already running from the previous run</p> <pre><code># This should already be running in your terminal\n$ uv run my-project\nINFO:     Started server process [20538]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:10002 (Press CTRL+C to quit)\n</code></pre> <p>Open up a new terminal in the same directory</p> <pre><code>source .venv/bin/activate\nuv run google-a2a-cli --agent http://localhost:10002\n</code></pre> <p>Note: This will only work if you've installed google-a2a from this pull request as the cli was not exposed previously.</p> <p>Otherwise you'll have to checkout the Google/A2A repository directly, navigate to the <code>samples/python</code> repository and run the cli directly</p> <p>You can then send messages to your server and pressing Enter</p> <pre><code>=========  starting a new task ========\n\nWhat do you want to send to the agent? (:q or quit to exit): Hello!\n</code></pre> <p>If everything is working correctly you'll see this in the response</p> <pre><code>\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"on_send_task received: Hello!\"}]}\n</code></pre> <p>To exit type <code>:q</code> and press Enter</p> Back Next"},{"location":"tutorials/python/8-agent-capabilities/","title":"Adding Agent Capabilities","text":"<p>Now that we have a basic A2A server running, let's add some more functionality. We'll explore how A2A can work asynchronously and stream responses.</p>"},{"location":"tutorials/python/8-agent-capabilities/#streaming","title":"Streaming","text":"<p>This allows clients to subscribe to the server and receive multiple updates instead of a single response. This can be useful for long running agent tasks, or where multiple Artifacts may streamed back to the client. See the Streaming Documentation</p> <p>First we'll declare our agent as ready for streaming. Open up <code>src/my_project/__init__.py</code> and update AgentCapabilities</p> <pre><code># ...\ndef main(host, port):\n  # ...\n  capabilities = AgentCapabilities(\n    streaming=True\n  )\n  # ...\n</code></pre> <p>Now in <code>src/my_project/task_manager.py</code> we'll have to implement <code>on_send_task_subscribe</code></p> <pre><code>import asyncio\n# ...\nclass MyAgentTaskManager(InMemoryTaskManager):\n  # ...\n  async def _stream_3_messages(self, request: SendTaskStreamingRequest):\n    task_id = request.params.id\n    received_text = request.params.message.parts[0].text\n\n    text_messages = [\"one\", \"two\", \"three\"]\n    for text in text_messages:\n      parts = [\n        {\n          \"type\": \"text\",\n          \"text\": f\"{received_text}: {text}\",\n        }\n      ]\n      message = Message(role=\"agent\", parts=parts)\n      is_last = text == text_messages[-1]\n      task_state = TaskState.COMPLETED if is_last else TaskState.WORKING\n      task_status = TaskStatus(\n        state=task_state,\n        message=message\n      )\n      task_update_event = TaskStatusUpdateEvent(\n        id=request.params.id,\n        status=task_status,\n        final=is_last,\n      )\n      await self.enqueue_events_for_sse(\n        request.params.id,\n        task_update_event\n      )\n\n  async def on_send_task_subscribe(\n    self,\n    request: SendTaskStreamingRequest\n  ) -&gt; AsyncIterable[SendTaskStreamingResponse] | JSONRPCResponse:\n    # Upsert a task stored by InMemoryTaskManager\n    await self.upsert_task(request.params)\n\n    task_id = request.params.id\n    # Create a queue of work to be done for this task\n    sse_event_queue = await self.setup_sse_consumer(task_id=task_id)\n\n    # Start the asynchronous work for this task\n    asyncio.create_task(self._stream_3_messages(request))\n\n    # Tell the client to expect future streaming responses\n    return self.dequeue_events_for_sse(\n      request_id=request.id,\n      task_id=task_id,\n      sse_event_queue=sse_event_queue,\n    )\n</code></pre> <p>Restart your A2A server to pickup the new changes and then rerun the cli</p> <pre><code>$ uv run google-a2a-cli --agent http://localhost:10002\n=========  starting a new task ========\n\nWhat do you want to send to the agent? (:q or quit to exit): Streaming?\n\n\"status\":{\"state\":\"working\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: one\"}]}\n\"status\":{\"state\":\"working\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: two\"}]}\n\"status\":{\"state\":\"completed\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: three\"}]}\n</code></pre> <p>Sometimes the agent might need additional input. For example, maybe the agent will ask the client if they'd like to keep repeating the 3 messages. In this case, the agent will respond with <code>TaskState.INPUT_REQUIRED</code> to which the client will then resend <code>send_task_streaming</code> with the same <code>task_id</code> and <code>session_id</code> but with an updated message providing the input required by the agent. On the server-side we'll update <code>on_send_task_subscribe</code> to handle this case.</p> <pre><code># ...\n\nclass MyAgentTaskManager(InMemoryTaskManager):\n  # ...\n  async def _stream_3_messages(self, request: SendTaskStreamingRequest):\n    # ...\n    async for message in messages:\n      # ...\n      # is_last = message == messages[-1] # Delete this line\n      task_state = TaskState.WORKING\n      # ...\n      task_update_event = TaskStatusUpdateEvent(\n        id=request.params.id,\n        status=task_status,\n        final=False,\n      )\n      # ...\n\n    ask_message = Message(\n      role=\"agent\",\n      parts=[\n        {\n          \"type\": \"text\",\n          \"text\": \"Would you like more messages? (Y/N)\"\n        }\n      ]\n    )\n    task_update_event = TaskStatusUpdateEvent(\n      id=request.params.id,\n      status=TaskStatus(\n        state=TaskState.INPUT_REQUIRED,\n        message=ask_message\n      ),\n      final=True,\n    )\n    await self.enqueue_events_for_sse(\n      request.params.id,\n      task_update_event\n    )\n  # ...\n  async def on_send_task_subscribe(\n    self,\n    request: SendTaskStreamingRequest\n  ) -&gt; AsyncIterable[SendTaskStreamingResponse] | JSONRPCResponse:\n    task_id = request.params.id\n    is_new_task = task_id in self.tasks\n    # Upsert a task stored by InMemoryTaskManager\n    await self.upsert_task(request.params)\n\n    received_text = request.params.message.parts[0].text\n    sse_event_queue = await self.setup_sse_consumer(task_id=task_id)\n    if not is_new_task and received_text == \"N\":\n      task_update_event = TaskStatusUpdateEvent(\n        id=request.params.id,\n        status=TaskStatus(\n          state=TaskState.COMPLETED,\n          message=Message(\n            role=\"agent\",\n            parts=[\n              {\n                \"type\": \"text\",\n                \"text\": \"All done!\"\n              }\n            ]\n          )\n        ),\n        final=True,\n      )\n      await self.enqueue_events_for_sse(\n        request.params.id,\n        task_update_event,\n      )\n    else:\n      asyncio.create_task(self._stream_3_messages(request))\n\n    return self.dequeue_events_for_sse(\n      request_id=request.id,\n      task_id=task_id,\n      sse_event_queue=sse_event_queue,\n    )\n</code></pre> <p>Now after restarting the server and running the cli, we can see the task will keep running until we tell the agent <code>N</code></p> <pre><code>$ uv run google-a2a-cli --agent http://localhost:10002\n=========  starting a new task ========\n\nWhat do you want to send to the agent? (:q or quit to exit): Streaming?\n\n\"status\":{\"state\":\"working\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: one\"}]}\n\"status\":{\"state\":\"working\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: two\"}]}\n\"status\":{\"state\":\"working\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Streaming?: three\"}]}\n\"status\":{\"state\":\"input-required\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"Would you like more messages? (Y/N)\"}]}\n\nWhat do you want to send to the agent? (:q or quit to exit): N\n\n\"status\":{\"state\":\"completed\",\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"All done!\"}]}\n</code></pre> <p>Congradulations! You now have an agent that is able to asynchronously perform work and ask users for input when needed.</p>"},{"location":"tutorials/python/8-agent-capabilities/#other-capabilities","title":"Other Capabilities","text":"<p>If you're interested, check out the documentation for other capabilities for your A2A agent. For now we'll jump into adding AI into A2A using a local LLM.</p> Back Next"},{"location":"tutorials/python/9-ollama-agent/","title":"Using a Local Ollama Model","text":"<p>Now we get to the exciting part. We're going to add AI to our A2A server.</p> <p>In this tutorial, we'll be setting up a local Ollama model and integrating it with our A2A server. However there are many other options such as using Google's Agent Development Kit (ADK). You can check out the sample projects on GitHub.</p>"},{"location":"tutorials/python/9-ollama-agent/#requirements","title":"Requirements","text":"<p>We'll be installing <code>ollama</code>, <code>langchain</code> as well as downloading an ollama model that supports MCP tools (for a future tutorial).</p> <ol> <li>Download ollama</li> <li>Run an ollama server</li> </ol> <pre><code># Note: if ollama is already running, you may get an error such as\n# Error: listen tcp 127.0.0.1:11434: bind: address already in use\n# On linux you can run systemctl stop ollama to stop ollama\nollama serve\n</code></pre> <ol> <li>Download a model from this list. We'll be using <code>qwq</code> as it supports <code>tools</code> (as shown by its tags) and runs on a 24GB graphics card</li> </ol> <pre><code>ollama pull qwq\n</code></pre> <ol> <li>Install <code>langchain</code></li> </ol> <pre><code>uv add langchain langchain-ollama langgraph\n</code></pre> <p>Now with ollama setup, we can start integrating it into our A2A server</p>"},{"location":"tutorials/python/9-ollama-agent/#integrating-ollama-into-our-a2a-server","title":"Integrating Ollama into our A2A server","text":"<p>First open up <code>src/my_project/__init__.py</code></p> <pre><code># ...\n\n@click.command()\n@click.option(\"--host\", default=\"localhost\")\n@click.option(\"--port\", default=10002)\n@click.option(\"--ollama-host\", default=\"http://127.0.0.1:11434\")\n@click.option(\"--ollama-model\", default=None)\ndef main(host, port, ollama_host, ollama_model):\n  # ...\n  capabilities = AgentCapabilities(\n    streaming=False # We'll leave streaming capabilities as an exercise for the reader\n  )\n  # ...\n  task_manager = MyAgentTaskManager(\n    ollama_host=ollama_host,\n    ollama_model=ollama_mode,\n  )\n  # ..\n</code></pre> <p>Now let's add AI functionality in <code>src/my_project/agent.py</code></p> <pre><code>from langchain_ollama import ChatOllama\nfrom langgraph.prebuilt import create_react_agent\nfrom langgraph.graph.graph import CompiledGraph\n\ndef create_ollama_agent(ollama_base_url: str, ollama_model: str):\n  ollama_chat_llm = ChatOllama(\n    base_url=ollama_base_url,\n    model=ollama_model,\n    temperature=0.2\n  )\n  agent = create_react_agent(ollama_chat_llm, tools=[])\n  return agent\n\nasync def run_ollama(ollama_agent: CompiledGraph, prompt: str):\n  agent_response = await ollama_agent.ainvoke(\n    {\"messages\": prompt }\n  )\n  message = agent_response[\"messages\"][-1].content\n  return str(message)\n</code></pre> <p>Finally let's call our ollama agent from <code>src/my_project/task_manager.py</code></p> <pre><code># ...\nfrom my_project.agent import create_ollama_agent, run_ollama\n\nclass MyAgentTaskManager(InMemoryTaskManager):\n  def __init__(\n    self,\n    ollama_host: str,\n    ollama_model: typing.Union[None, str]\n  ):\n    super().__init__()\n    if ollama_model is not None:\n      self.ollama_agent = create_ollama_agent(\n        ollama_base_url=ollama_host,\n        ollama_model=ollama_model\n      )\n    else:\n      self.ollama_agent = None\n\n  async def on_send_task(self, request: SendTaskRequest) -&gt; SendTaskResponse:\n    # ...\n    received_text = request.params.message.parts[0].text\n    response_text = f\"on_send_task received: {received_text}\"\n    if self.ollama_agent is not None:\n      response_text = await run_ollama(ollama_agent=self.ollama_agent, prompt=received_text)\n\n    task = await self._update_task(\n      task_id=task_id,\n      task_state=TaskState.COMPLETED,\n      response_text=response_text\n    )\n\n    # Send the response\n    return SendTaskResponse(id=request.id, result=task)\n\n  # ...\n</code></pre> <p>Lets test it out!</p> <p>First rerun our A2A server replacing <code>qwq</code> with the ollama model you downloaded</p> <pre><code>uv run my-project --ollama-host http://127.0.0.1:11434 --ollama-model qwq\n</code></pre> <p>And then rerun the cli</p> <pre><code>uv run google-a2a-cli --agent http://localhost:10002\n</code></pre> <p>Note, if you're using a large model, it may take a while to load. The cli may timeout. In which case rerun the cli once the ollama server has finished loading the model.</p> <p>You should see something like the following</p> <pre><code>=========  starting a new task ========\n\nWhat do you want to send to the agent? (:q or quit to exit): hey\n\n\"message\":{\"role\":\"agent\",\"parts\":[{\"type\":\"text\",\"text\":\"&lt;think&gt;\\nOkay, the user said \\\"hey\\\". That's pretty casual. I should respond in a friendly way. Maybe ask how I can help them today. Keep it open-ended so they feel comfortable sharing what they need. Let me make sure my tone is positive and approachable. Alright, something like, \\\"Hey there! How can I assist you today?\\\" Yeah, that sounds good.\\n&lt;/think&gt;\\n\\nHey there! How can I assist you today? \ud83d\ude0a\"}]}\n</code></pre> <p>Congratulations! You now have an A2A server generating responses using an AI model!</p> Back Next"}]}